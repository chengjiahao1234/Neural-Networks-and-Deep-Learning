{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“nmt.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [
        "4BIpGwANoQOg",
        "pbvpn4MaV0I1",
        "bRWfRdmVVjUl",
        "0yh08KhgnA30",
        "ecEq4TP2lZ4Z",
        "RWwA6OGqlaTq",
        "AJSafHSAmu_w",
        "73_p8d5EmvOJ",
        "vYPae08Io1Fi",
        "9tcpUFKqo2Oi",
        "z1hDi020rT36",
        "MBnBXRG8mvcn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjPTaRB4mpCd"
      },
      "source": [
        "# Colab FAQ\n",
        "\n",
        "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "You need to use the colab GPU for this assignmentby selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9IS9B9-yUU5"
      },
      "source": [
        "## Setup PyTorch\n",
        "All files are stored at /content/csc421/a3/ folder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axbuunY8UdTB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-6MQhMOlHXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "d657bdb3-9a49-47e7-ad78-7742bf806cf0"
      },
      "source": [
        "######################################################################\n",
        "# Setup python environment and change the current working directory\n",
        "######################################################################\n",
        "!pip install torch torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "%mkdir -p ./content/csc421/a3/\n",
        "%cd ./content/csc421/a3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Collecting pillow>=4.1.1\n",
            "  Using cached https://files.pythonhosted.org/packages/1f/6d/b719ae8e21660a6a962636896dc4b7d657ef451a3ab941516401846ac5cb/Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-8.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Processing /root/.cache/pip/wheels/4f/0a/2a/7e3391063af230fac4b5fdb4cc93adcb1d99af325b623cea03/Pillow-4.0.0-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.7/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 8.1.2\n",
            "    Uninstalling Pillow-8.1.2:\n",
            "      Successfully uninstalled Pillow-8.1.2\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/content/csc421/a3/content/csc421/a3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DaTdRNuUra7"
      },
      "source": [
        "# Helper code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BIpGwANoQOg"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-UJHBYZkh7f"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "import pickle as pkl\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_file(fname,\n",
        "             origin,\n",
        "             untar=False,\n",
        "             extract=False,\n",
        "             archive_format='auto',\n",
        "             cache_dir='data'):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + '.tar.gz'\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "    \n",
        "    print(fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print('Downloading data from', origin)\n",
        "\n",
        "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print('Extracting file.')\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "def to_var(tensor, cuda):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n",
        "\n",
        "\n",
        "def create_dir_if_not_exists(directory):\n",
        "    \"\"\"Creates a directory if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def save_loss_plot(train_losses, val_losses, opts):\n",
        "    \"\"\"Saves a plot of the training and validation loss curves.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_losses)), train_losses)\n",
        "    plt.plot(range(len(val_losses)), val_losses)\n",
        "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_loss_comparison_lstm(l1, l2, o1, o2, fn, s=500):\n",
        "    \"\"\"Plot comparison of training and val loss curves from LSTM runs.\n",
        "    \n",
        "    Arguments:\n",
        "        l1: Tuple of lists containing training / val losses for model 1.\n",
        "        l2: Tuple of lists containing training / val losses for model 2.\n",
        "        o1: Options for model 1.\n",
        "        o2: Options for model 2.\n",
        "        fn: Output file name.\n",
        "        s: Number of training iterations to average over.\n",
        "    \"\"\"\n",
        "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
        "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    ax[0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
        "    ax[0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
        "    ax[0].title.set_text('Train Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
        "\n",
        "    # Validation losses are assumed to be by epoch\n",
        "    ax[1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
        "    ax[1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
        "    ax[1].title.set_text('Val Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
        "\n",
        "    ax[0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
        "    ax[0].set_ylabel(\"Loss\", fontsize=10)\n",
        "    ax[1].set_xlabel(\"Epochs\", fontsize=10)\n",
        "    ax[1].set_ylabel(\"Loss\", fontsize=10)\n",
        "    ax[0].legend(loc=\"upper right\")\n",
        "    ax[1].legend(loc=\"upper right\")\n",
        "\n",
        "    fig.suptitle('LSTM Performance by Dataset', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    fig.subplots_adjust(top=0.85)\n",
        "    plt.legend()\n",
        "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_loss_comparison_by_dataset(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
        "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
        "    runs in Part 3, comparing by dataset while holding hidden size constant.\n",
        "\n",
        "    Models within each pair (l1, l2) and (l3, l4) have the same hidden sizes.\n",
        "\n",
        "    Arguments:\n",
        "        l1: Tuple of lists containing training / val losses for model 1.\n",
        "        l2: Tuple of lists containing training / val losses for model 2.\n",
        "        l3: Tuple of lists containing training / val losses for model 3.\n",
        "        l4: Tuple of lists containing training / val losses for model 4.\n",
        "        o1: Options for model 1.\n",
        "        o2: Options for model 2.\n",
        "        o3: Options for model 3.\n",
        "        o4: Options for model 4.\n",
        "        fn: Output file name.\n",
        "        s: Number of training iterations to average over.\n",
        "    \"\"\"\n",
        "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
        "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
        "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
        "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
        "\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
        "    ax[0][0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
        "    ax[0][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
        "\n",
        "    # Validation losses are assumed to be by epoch\n",
        "    ax[0][1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
        "    ax[0][1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
        "    ax[0][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
        "\n",
        "    ax[1][0].plot(range(len(mean_l3)), mean_l3, label='ds=' + o3.data_file_name)\n",
        "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='ds=' + o4.data_file_name)\n",
        "    ax[1][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o3.hidden_size))\n",
        "\n",
        "    ax[1][1].plot(range(len(l3[1])), l3[1], label='ds=' + o3.data_file_name)\n",
        "    ax[1][1].plot(range(len(l4[1])), l4[1], label='ds=' + o4.data_file_name)\n",
        "    ax[1][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o4.hidden_size))\n",
        "\n",
        "    for i in range(2):\n",
        "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
        "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
        "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
        "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
        "        ax[i][0].legend(loc=\"upper right\")\n",
        "        ax[i][1].legend(loc=\"upper right\")\n",
        "\n",
        "    fig.suptitle(\"Performance by Dataset Size\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    fig.subplots_adjust(top=0.9)\n",
        "    plt.legend()\n",
        "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
        "    plt.close()\n",
        "\n",
        "def save_loss_comparison_by_hidden(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
        "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
        "    runs in Part 3, comparing by hidden size while holding dataset constant.\n",
        "\n",
        "    Models within each pair (l1, l3) and (l2, l4) have the same dataset.\n",
        "\n",
        "    Arguments:\n",
        "        l1: Tuple of lists containing training / val losses for model 1.\n",
        "        l2: Tuple of lists containing training / val losses for model 2.\n",
        "        l3: Tuple of lists containing training / val losses for model 3.\n",
        "        l4: Tuple of lists containing training / val losses for model 4.\n",
        "        o1: Options for model 1.\n",
        "        o2: Options for model 2.\n",
        "        o3: Options for model 3.\n",
        "        o4: Options for model 4.\n",
        "        fn: Output file name.\n",
        "        s: Number of training iterations to average over.\n",
        "    \"\"\"\n",
        "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
        "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
        "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
        "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
        "\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='hid_size=' + str(o1.hidden_size))\n",
        "    ax[0][0].plot(range(len(mean_l3)), mean_l3, label='hid_size=' + str(o3.hidden_size))\n",
        "    ax[0][0].title.set_text('Train Loss | Dataset = ' + o1.data_file_name)\n",
        "\n",
        "    # Validation losses are assumed to be by epoch\n",
        "    ax[0][1].plot(range(len(l1[1])), l1[1], label='hid_size=' + str(o1.hidden_size))\n",
        "    ax[0][1].plot(range(len(l3[1])), l3[1], label='hid_size=' + str(o3.hidden_size))\n",
        "    ax[0][1].title.set_text('Val Loss | Dataset = ' + o1.data_file_name)\n",
        "\n",
        "    ax[1][0].plot(range(len(mean_l2)), mean_l2, label='hid_size=' + str(o2.hidden_size))\n",
        "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='hid_size=' + str(o4.hidden_size))\n",
        "    ax[1][0].title.set_text('Train Loss | Dataset = ' + o3.data_file_name)\n",
        "\n",
        "    ax[1][1].plot(range(len(l2[1])), l2[1], label='hid_size=' + str(o2.hidden_size))\n",
        "    ax[1][1].plot(range(len(l4[1])), l4[1], label='hid_size=' + str(o4.hidden_size))\n",
        "    ax[1][1].title.set_text('Val Loss | Dataset = ' + o4.data_file_name)\n",
        "\n",
        "    for i in range(2):\n",
        "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
        "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
        "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
        "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
        "        ax[i][0].legend(loc=\"upper right\")\n",
        "        ax[i][1].legend(loc=\"upper right\")\n",
        "\n",
        "    fig.suptitle(\"Performance by Hidden State Size\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    fig.subplots_adjust(top=0.9)\n",
        "    plt.legend()\n",
        "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def checkpoint(encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
        "    contains the char_to_index and index_to_char mappings, and the start_token\n",
        "    and end_token values.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
        "        torch.save(encoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
        "        torch.save(decoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
        "        pkl.dump(idx_dict, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbvpn4MaV0I1"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVT4TNTOV3Eg"
      },
      "source": [
        "def read_lines(filename):\n",
        "    \"\"\"Read a file and split it into lines.\n",
        "    \"\"\"\n",
        "    lines = open(filename).read().strip().lower().split('\\n')\n",
        "    return lines\n",
        "\n",
        "\n",
        "def read_pairs(filename):\n",
        "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
        "\n",
        "    Returns:\n",
        "        source_words: A list of the first word in each line of the file.\n",
        "        target_words: A list of the second word in each line of the file.\n",
        "    \"\"\"\n",
        "    lines = read_lines(filename)\n",
        "    source_words, target_words = [], []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            source, target = line.split()\n",
        "            source_words.append(source)\n",
        "            target_words.append(target)\n",
        "    return source_words, target_words\n",
        "\n",
        "\n",
        "def all_alpha_or_dash(s):\n",
        "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
        "    \"\"\"\n",
        "    return all(c.isalpha() or c == '-' for c in s)\n",
        "\n",
        "\n",
        "def filter_lines(lines):\n",
        "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
        "    \"\"\"\n",
        "    return [line for line in lines if all_alpha_or_dash(line)]\n",
        "\n",
        "\n",
        "def load_data(file_name):\n",
        "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
        "    \"\"\"\n",
        "    path = \"./data/{}.txt\".format(file_name)\n",
        "    source_lines, target_lines = read_pairs(path)\n",
        "\n",
        "    # Filter lines\n",
        "    source_lines = filter_lines(source_lines)\n",
        "    target_lines = filter_lines(target_lines)\n",
        "\n",
        "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
        "\n",
        "    # Create a dictionary mapping each character to a unique index\n",
        "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
        "\n",
        "    # Add start and end tokens to the dictionary\n",
        "    start_token = len(char_to_index)\n",
        "    end_token = len(char_to_index) + 1\n",
        "    char_to_index['SOS'] = start_token\n",
        "    char_to_index['EOS'] = end_token\n",
        "\n",
        "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
        "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
        "\n",
        "    # Store the final size of the vocabulary\n",
        "    vocab_size = len(char_to_index)\n",
        "\n",
        "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
        "\n",
        "    idx_dict = { 'char_to_index': char_to_index,\n",
        "                 'index_to_char': index_to_char,\n",
        "                 'start_token': start_token,\n",
        "                 'end_token': end_token }\n",
        "\n",
        "    return line_pairs, vocab_size, idx_dict\n",
        "\n",
        "\n",
        "def create_dict(pairs):\n",
        "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
        "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
        "    all source indexes and the other containing all corresponding target indexes.\n",
        "    Within a batch, all the source words are the same length, and all the target words are\n",
        "    the same length.\n",
        "    \"\"\"\n",
        "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
        "\n",
        "    d = defaultdict(list)\n",
        "    for (s,t) in unique_pairs:\n",
        "        d[(len(s), len(t))].append((s,t))\n",
        "\n",
        "    return d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRWfRdmVVjUl"
      },
      "source": [
        "## Training and evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa5-onJhoSeM"
      },
      "source": [
        "def string_to_index_list(s, char_to_index, end_token):\n",
        "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
        "    \"\"\"\n",
        "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
        "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
        "    word independently, and then stitching the words back together with spaces between them.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
        "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
        "\n",
        "\n",
        "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a given string from English to Pig-Latin.\n",
        "    \"\"\"\n",
        "\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_last_hidden, encoder_last_cell = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_last_hidden\n",
        "    decoder_cell = encoder_last_cell\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "        ## slow decoding, recompute everything at each time\n",
        "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
        "\n",
        "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "        ni = ni[-1] #latest output token\n",
        "\n",
        "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "\n",
        "        if ni == end_token:\n",
        "            break\n",
        "        else:\n",
        "            gen_string = \"\".join(\n",
        "                [index_to_char[int(item)] \n",
        "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_hidden, encoder_cell = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    produced_end_token = False\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "        ## slow decoding, recompute everything at each time\n",
        "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
        "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "        ni = ni[-1] #latest output token\n",
        "\n",
        "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "\n",
        "        if ni == end_token:\n",
        "            break\n",
        "        else:\n",
        "            gen_string = \"\".join(\n",
        "                [index_to_char[int(item)] \n",
        "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "    \n",
        "    if isinstance(attention_weights, tuple):\n",
        "      ## transformer's attention mweights\n",
        "      attention_weights, self_attention_weights = attention_weights\n",
        "    \n",
        "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
        "    \n",
        "    for i in range(len(all_attention_weights)):\n",
        "        attention_weights_matrix = all_attention_weights[i].squeeze()\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
        "        fig.colorbar(cax)\n",
        "\n",
        "        # Set up axes\n",
        "        ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
        "        ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
        "\n",
        "        # Show label at every tick\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        # Add title\n",
        "        plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
        "        plt.tight_layout()\n",
        "        plt.grid('off')\n",
        "        plt.show()\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
        "    \"\"\"Train/Evaluate the model on a dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
        "        opts: The command-line arguments.\n",
        "\n",
        "    Returns:\n",
        "        mean_loss: The average loss over all batches from data_dict.\n",
        "    \"\"\"\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    losses = []\n",
        "    for key in data_dict:\n",
        "        input_strings, target_strings = zip(*data_dict[key])\n",
        "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
        "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
        "\n",
        "        num_tensors = len(input_tensors)\n",
        "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
        "\n",
        "        for i in range(num_batches):\n",
        "\n",
        "            start = i * opts.batch_size\n",
        "            end = start + opts.batch_size\n",
        "\n",
        "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
        "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
        "\n",
        "            # The batch size may be different in each epoch\n",
        "            BS = inputs.size(0)\n",
        "\n",
        "            encoder_annotations, encoder_hidden, encoder_cell = encoder(inputs)\n",
        "\n",
        "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
        "            decoder_hidden = encoder_hidden\n",
        "            decoder_cell = encoder_cell\n",
        "\n",
        "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
        "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
        "\n",
        "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
        "\n",
        "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
        "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
        "            targets_flatten = targets.view(-1)\n",
        "            \n",
        "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## training if an optimizer is provided\n",
        "            if optimizer:\n",
        "              # Zero gradients\n",
        "              optimizer.zero_grad()\n",
        "              # Compute gradients\n",
        "              loss.backward()\n",
        "              # Update the parameters of the encoder and decoder\n",
        "              optimizer.step()\n",
        "\n",
        "    return losses\n",
        "\n",
        "  \n",
        "\n",
        "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
        "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
        "        * Prints training and val loss each epoch.\n",
        "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
        "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
        "        * Returns loss curves for comparison\n",
        "\n",
        "    Arguments:\n",
        "        train_dict: The training word pairs, organized by source and target lengths.\n",
        "        val_dict: The validation word pairs, organized by source and target lengths.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
        "        opts: The command-line arguments.\n",
        "    \n",
        "    Returns:\n",
        "        losses: Lists containing training and validation loss curves.\n",
        "    \"\"\"\n",
        "\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
        "\n",
        "    best_val_loss = 1e6\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    mean_train_losses = []\n",
        "    mean_val_losses = []\n",
        "\n",
        "    early_stopping_counter = 0\n",
        "    \n",
        "    for epoch in range(opts.nepochs):\n",
        "\n",
        "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
        "        \n",
        "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
        "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
        "\n",
        "        mean_train_loss = np.mean(train_loss)\n",
        "        mean_val_loss = np.mean(val_loss)\n",
        "\n",
        "        if mean_val_loss < best_val_loss:\n",
        "            checkpoint(encoder, decoder, idx_dict, opts)\n",
        "            best_val_loss = mean_val_loss\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        \n",
        "        if early_stopping_counter > opts.early_stopping_patience:\n",
        "            print(\"Validation loss has not improved in {} epochs, stopping early\".format(opts.early_stopping_patience))\n",
        "            print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
        "            return (train_losses, mean_val_losses)\n",
        "\n",
        "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
        "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, mean_train_loss, mean_val_loss, gen_string))\n",
        "\n",
        "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
        "        loss_log.flush()\n",
        "\n",
        "        train_losses += train_loss\n",
        "        val_losses += val_loss\n",
        "\n",
        "        mean_train_losses.append(mean_train_loss)\n",
        "        mean_val_losses.append(mean_val_loss)\n",
        "\n",
        "        save_loss_plot(mean_train_losses, mean_val_losses, opts)\n",
        "\n",
        "    print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
        "    return (train_losses, mean_val_losses)\n",
        "\n",
        "\n",
        "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
        "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Data Stats'.center(80))\n",
        "    print('-' * 80)\n",
        "    for pair in line_pairs[:5]:\n",
        "        print(pair)\n",
        "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
        "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
        "    print('Vocab size: {}'.format(vocab_size))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
        "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
        "\n",
        "    # Split the line pairs into an 80% train and 20% val split\n",
        "    num_lines = len(line_pairs)\n",
        "    num_train = int(0.8 * num_lines)\n",
        "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
        "\n",
        "    # Group the data by the lengths of the source and target words, to form batches\n",
        "    train_dict = create_dict(train_pairs)\n",
        "    val_dict = create_dict(val_pairs)\n",
        "\n",
        "    ##########################################################################\n",
        "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
        "    ##########################################################################\n",
        "    if opts.encoder_type == \"rnn\":\n",
        "        encoder = LSTMEncoder(vocab_size=vocab_size, \n",
        "                              hidden_size=opts.hidden_size, \n",
        "                              opts=opts)\n",
        "    elif opts.encoder_type == \"transformer\":\n",
        "        encoder = TransformerEncoder(vocab_size=vocab_size, \n",
        "                                     hidden_size=opts.hidden_size, \n",
        "                                     num_layers=opts.num_transformer_layers,\n",
        "                                     opts=opts)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    if opts.decoder_type == 'rnn':\n",
        "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
        "                             hidden_size=opts.hidden_size)\n",
        "    elif opts.decoder_type == 'rnn_attention':\n",
        "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
        "                                      hidden_size=opts.hidden_size, \n",
        "                                      attention_type=opts.attention_type)\n",
        "    elif opts.decoder_type == 'transformer':\n",
        "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
        "                                     hidden_size=opts.hidden_size, \n",
        "                                     num_layers=opts.num_transformer_layers)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    #### setup checkpoint path\n",
        "    model_name = 'h{}-bs{}-{}-{}'.format(opts.hidden_size, \n",
        "                                      opts.batch_size, \n",
        "                                      opts.decoder_type,\n",
        "                                      opts.data_file_name)\n",
        "    opts.checkpoint_path = model_name\n",
        "    create_dir_if_not_exists(opts.checkpoint_path)\n",
        "    ####\n",
        "\n",
        "    if opts.cuda:\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "        print(\"Moved models to GPU!\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
        "\n",
        "    try:\n",
        "        losses = training_loop(train_dict, val_dict, idx_dict, encoder, \n",
        "                               decoder, criterion, optimizer, opts)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return encoder, decoder, losses\n",
        "      \n",
        "    return encoder, decoder, losses\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yh08KhgnA30"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aROU2xZanDKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6275fb2a-0430-4298-a25a-8c58b5dfe818"
      },
      "source": [
        "######################################################################\n",
        "# Download Translation datasets\n",
        "######################################################################\n",
        "data_fpath = get_file(fname='pig_latin_small.txt', \n",
        "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_small.txt', \n",
        "                         untar=False)\n",
        "\n",
        "data_fpath = get_file(fname='pig_latin_large.txt', \n",
        "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_large.txt', \n",
        "                         untar=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/pig_latin_small.txt\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_small.txt\n",
            "data/pig_latin_large.txt\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_large.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDYMr7NclZdw"
      },
      "source": [
        "# Part 1: Long Short-Term Memory Unit (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCae1mOUlZrC"
      },
      "source": [
        "## Step 1: LSTM Cell\n",
        "Please implement the Long Short-Term Memory class defined in the next cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOnALRQkkjDO"
      },
      "source": [
        "class MyLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        self.Wii = nn.Linear(input_size, hidden_size)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wif = nn.Linear(input_size, hidden_size)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wig = nn.Linear(input_size, hidden_size)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wio = nn.Linear(input_size, hidden_size)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        \"\"\"Forward pass of the LSTM computation for one time step.\n",
        "\n",
        "        Arguments\n",
        "            x: batch_size x input_size\n",
        "            h_prev: batch_size x hidden_size\n",
        "            c_prev: batch_size x hidden_size\n",
        "\n",
        "        Returns:\n",
        "            h_new: batch_size x hidden_size\n",
        "            c_new: batch_size x hidden_size\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        i = torch.sigmoid(self.Wii(x) + self.Whi(h_prev))\n",
        "        f = torch.sigmoid(self.Wif(x) + self.Whf(h_prev))\n",
        "        g = torch.tanh(self.Wig(x) + self.Whg(h_prev))\n",
        "        o = torch.sigmoid(self.Wio(x) + self.Who(h_prev))\n",
        "        c_new = torch.mul(f, c_prev) + torch.mul(i, g)\n",
        "        h_new = torch.mul(o, torch.tanh(c_new))\n",
        "        return h_new, c_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecEq4TP2lZ4Z"
      },
      "source": [
        "## Step 2: LSTM Encoder\n",
        "Please inspect the following recurrent encoder/decoder implementations. Make sure to run the cells before proceeding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jDNim2fmVJV"
      },
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, opts):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.opts = opts\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.lstm = MyLSTMCell(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass of the encoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
        "\n",
        "        Returns:\n",
        "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len = inputs.size()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        cell = self.init_hidden(batch_size)\n",
        "\n",
        "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "        annotations = []\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
        "            hidden, cell = self.lstm(x, hidden, cell)\n",
        "            annotations.append(hidden)\n",
        "\n",
        "        annotations = torch.stack(annotations, dim=1)\n",
        "        return annotations, hidden, cell\n",
        "\n",
        "    def init_hidden(self, bs):\n",
        "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
        "        of a batch of sequences.\n",
        "\n",
        "        Arguments:\n",
        "            bs: The batch size for the initial hidden state.\n",
        "\n",
        "        Returns:\n",
        "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwizYM9ma4p"
      },
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = MyLSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
        "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
        "            annotations: This is not used here. It just maintains consistency with the\n",
        "                    interface used by the AttentionDecoder class.\n",
        "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
        "            cell_init: The cell states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            None\n",
        "        \"\"\"        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        h_prev = hidden_init\n",
        "        c_prev = cell_init\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
        "            h_prev, c_prev = self.rnn(x, h_prev, c_prev)  # batch_size x hidden_size\n",
        "            hiddens.append(h_prev)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, None  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSDTbsydlaGI"
      },
      "source": [
        "## Step 3: Training and Analysis\n",
        "Train the following language model comprised of recurrent encoder and decoders. \n",
        "\n",
        "First, we train on the smaller dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVuXTozTPF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07fe3bc-4d80-414d-96ac-32b6a90b8653"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "rnn_args_s = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_small',\n",
        "              'cuda':True,\n",
        "              'nepochs':50,\n",
        "              'checkpoint_dir':\"checkpoints\",\n",
        "              'learning_rate':0.005,\n",
        "              'lr_decay':0.99,\n",
        "              'early_stopping_patience':20,\n",
        "              'batch_size':64,\n",
        "              'hidden_size':32,\n",
        "              'encoder_type': 'rnn', # options: rnn / transformer\n",
        "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': '',  # options: additive / scaled_dot\n",
        "}\n",
        "rnn_args_s.update(args_dict)\n",
        "\n",
        "print_opts(rnn_args_s)\n",
        "rnn_encode_s, rnn_decoder_s, rnn_losses_s = train(rnn_args_s)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encode_s, rnn_decoder_s, None, rnn_args_s)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_small                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 50                                     \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                early_stopping_patience: 20                                     \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 32                                     \n",
            "                           encoder_type: rnn                                    \n",
            "                           decoder_type: rnn                                    \n",
            "                         attention_type:                                        \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('inheritor', 'inheritorway')\n",
            "('schemes', 'emesschay')\n",
            "('bathed', 'athedbay')\n",
            "('audacity', 'audacityway')\n",
            "('significant', 'ignificantsay')\n",
            "Num unique word pairs: 3198\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.348 | Val loss: 2.088 | Gen: ay-ay ay-ay intay-intay-intay-in intay intay-intay\n",
            "Epoch:   1 | Train loss: 1.858 | Val loss: 1.892 | Gen: atay ay-ay ontingay-ontay-onday itay itesay-onday\n",
            "Epoch:   2 | Train loss: 1.685 | Val loss: 1.773 | Gen: esay aray oontingay-oray isway ootionday\n",
            "Epoch:   3 | Train loss: 1.549 | Val loss: 1.670 | Gen: esay alway oontiontentay isway ootionway\n",
            "Epoch:   4 | Train loss: 1.430 | Val loss: 1.702 | Gen: etay aray intiontingay iway orlyay\n",
            "Epoch:   5 | Train loss: 1.347 | Val loss: 1.498 | Gen: etay alway ontionsionday isway orfionway\n",
            "Epoch:   6 | Train loss: 1.254 | Val loss: 1.479 | Gen: etay arway oncountionday isway orfionway\n",
            "Epoch:   7 | Train loss: 1.180 | Val loss: 1.387 | Gen: etay arway ooncouceday-oday isway oficay\n",
            "Epoch:   8 | Train loss: 1.108 | Val loss: 1.366 | Gen: etay alway ongssay-ondenday isway ofsay-oway\n",
            "Epoch:   9 | Train loss: 1.062 | Val loss: 1.365 | Gen: etay arfay onconcay-ooredway isway ofsay-odway\n",
            "Epoch:  10 | Train loss: 1.025 | Val loss: 1.268 | Gen: etay arway oncecouceday isway ofsicay\n",
            "Epoch:  11 | Train loss: 0.967 | Val loss: 1.269 | Gen: etay arfay ooncedingnay-oway isway orfingway\n",
            "Epoch:  12 | Train loss: 0.927 | Val loss: 1.236 | Gen: etay arway ongencingtay isway ofsingway\n",
            "Epoch:  13 | Train loss: 0.888 | Val loss: 1.221 | Gen: etay arway ontionclicay isway ofsingway\n",
            "Epoch:  14 | Train loss: 0.864 | Val loss: 1.159 | Gen: ethay ariway ongencionmay isway ofsingway\n",
            "Epoch:  15 | Train loss: 0.816 | Val loss: 1.170 | Gen: ethay arfay ontionclicay isway ofsingway\n",
            "Epoch:  16 | Train loss: 0.798 | Val loss: 1.109 | Gen: ethay ariway ongioncliendway isway ofsicay\n",
            "Epoch:  17 | Train loss: 0.756 | Val loss: 1.101 | Gen: ethay arfay ontioncligay isway olfsay\n",
            "Epoch:  18 | Train loss: 0.732 | Val loss: 1.079 | Gen: ethay awlysay ongedshingnay isway ofsicay\n",
            "Epoch:  19 | Train loss: 0.709 | Val loss: 1.080 | Gen: ethay aisway ongingtingray isway ofsicay\n",
            "Epoch:  20 | Train loss: 0.693 | Val loss: 1.038 | Gen: ethay aisway onghingingray isway ofsighway\n",
            "Epoch:  21 | Train loss: 0.666 | Val loss: 1.038 | Gen: ethay aisway ondicingtay-olway isway ofsicay\n",
            "Epoch:  22 | Train loss: 0.646 | Val loss: 1.014 | Gen: ethay awlyway ondigingtay-onway isway officeway\n",
            "Epoch:  23 | Train loss: 0.615 | Val loss: 1.017 | Gen: ethay away ondicingtay-owlay isway ofsicay\n",
            "Epoch:  24 | Train loss: 0.597 | Val loss: 1.016 | Gen: ethay aisway ondicingtay-owlay isway officeway\n",
            "Epoch:  25 | Train loss: 0.582 | Val loss: 1.017 | Gen: ethay aisway ondioncinglay isway ouliceway\n",
            "Epoch:  26 | Train loss: 0.570 | Val loss: 1.025 | Gen: ethay aisway ondicingteray isway oulstlay\n",
            "Epoch:  27 | Train loss: 0.560 | Val loss: 0.991 | Gen: ethay aisway ondicingtay-olway isway oulityway\n",
            "Epoch:  28 | Train loss: 0.550 | Val loss: 0.984 | Gen: ethay aisway ondicingtencay isway ousilyway\n",
            "Epoch:  29 | Train loss: 0.528 | Val loss: 0.960 | Gen: ethay aisway ondicechiontway isway oustlyway\n",
            "Epoch:  30 | Train loss: 0.509 | Val loss: 0.932 | Gen: ethay aisway ondicingtionway isway ousilyway\n",
            "Epoch:  31 | Train loss: 0.491 | Val loss: 0.940 | Gen: ethay aisway ondicecoltbay isway oushidfay\n",
            "Epoch:  32 | Train loss: 0.484 | Val loss: 0.943 | Gen: ethay aisway ondicetinglay isway oustlyway\n",
            "Epoch:  33 | Train loss: 0.489 | Val loss: 0.969 | Gen: ethay aiway ondicingtay-owlay isway oushhay\n",
            "Epoch:  34 | Train loss: 0.474 | Val loss: 0.933 | Gen: ethay aisway ondicingtionway isway ouslitway\n",
            "Epoch:  35 | Train loss: 0.468 | Val loss: 0.957 | Gen: ethay aisway ondicingentway isway oushhay\n",
            "Epoch:  36 | Train loss: 0.450 | Val loss: 0.917 | Gen: ethay aisway ondicingtionway isway ouringway\n",
            "Epoch:  37 | Train loss: 0.431 | Val loss: 0.934 | Gen: ethay aisway ondicinghenay isway ouslitway\n",
            "Epoch:  38 | Train loss: 0.426 | Val loss: 0.891 | Gen: ethay aisway ondicinghenay isway oushhay\n",
            "Epoch:  39 | Train loss: 0.421 | Val loss: 0.933 | Gen: ethay airway ondicingtionway isway ourighway\n",
            "Epoch:  40 | Train loss: 0.421 | Val loss: 0.944 | Gen: ethay aisway ondicingedtay isway oushhay\n",
            "Epoch:  41 | Train loss: 0.418 | Val loss: 0.905 | Gen: ethay airway ondicingtionway isway oushhay\n",
            "Epoch:  42 | Train loss: 0.390 | Val loss: 0.893 | Gen: ethay airway ondicingtingway isway ouringway\n",
            "Epoch:  43 | Train loss: 0.374 | Val loss: 0.875 | Gen: ethay airway ondicingetjay isway oushhay\n",
            "Epoch:  44 | Train loss: 0.365 | Val loss: 0.906 | Gen: ethay airway ondicinghentway isway oushhay\n",
            "Epoch:  45 | Train loss: 0.371 | Val loss: 0.909 | Gen: ethay airway ondicingtionway isway oushhay\n",
            "Epoch:  46 | Train loss: 0.359 | Val loss: 0.908 | Gen: ethay aisway ondicingetjay isway oushhay\n",
            "Epoch:  47 | Train loss: 0.349 | Val loss: 0.882 | Gen: ethay airway ondicingtionway isway oushhay\n",
            "Epoch:  48 | Train loss: 0.339 | Val loss: 0.890 | Gen: ethay airway ondicingtionway isway oushhay\n",
            "Epoch:  49 | Train loss: 0.338 | Val loss: 0.931 | Gen: ehtay airway ondicinionteway isway oushhay\n",
            "Obtained lowest validation loss of: 0.8753384565003216\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tehtay airway ondicinionteway isway oushhay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mR97V_NtER6"
      },
      "source": [
        "Next, we train on the larger dataset. This experiment investigates if increasing dataset size improves model generalization on the validation set. \n",
        "\n",
        "For a fair comparison, the number of iterations (not number of epochs) for each run should be similar. This is done in a rough and dirty way by adjusting the batch size so approximately the same number of batches is processed per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3YLrAjsmx_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bb468d-561d-46d2-dbc0-150225850ae3"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "rnn_args_l = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_large',\n",
        "              'cuda':True,\n",
        "              'nepochs':50,\n",
        "              'checkpoint_dir':\"checkpoints\",\n",
        "              'learning_rate':0.005,\n",
        "              'lr_decay':0.99,\n",
        "              'early_stopping_patience':10,\n",
        "              'batch_size':512,\n",
        "              'hidden_size':32,\n",
        "              'encoder_type': 'rnn', # options: rnn / transformer\n",
        "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': '',  # options: additive / scaled_dot\n",
        "}\n",
        "rnn_args_l.update(args_dict)\n",
        "\n",
        "print_opts(rnn_args_l)\n",
        "rnn_encode_l, rnn_decoder_l, rnn_losses_l = train(rnn_args_l)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encode_l, rnn_decoder_l, None, rnn_args_l)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_large                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 50                                     \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                early_stopping_patience: 10                                     \n",
            "                             batch_size: 512                                    \n",
            "                            hidden_size: 32                                     \n",
            "                           encoder_type: rnn                                    \n",
            "                           decoder_type: rnn                                    \n",
            "                         attention_type:                                        \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('newcomers', 'ewcomersnay')\n",
            "('lq', 'lqay')\n",
            "('contracting', 'ontractingcay')\n",
            "('garde', 'ardegay')\n",
            "('transexual', 'ansexualtray')\n",
            "Num unique word pairs: 22402\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.346 | Val loss: 2.046 | Gen: ay-ay ay-ay-ay ontay-ay-ay-ay-ay ay ontay-ay\n",
            "Epoch:   1 | Train loss: 1.891 | Val loss: 1.845 | Gen: ay-ay ay-ay ontay-intay-eday ay ontay-intay\n",
            "Epoch:   2 | Train loss: 1.713 | Val loss: 1.737 | Gen: ay-ay away ontay-ertay-eray isway otay-intay\n",
            "Epoch:   3 | Train loss: 1.595 | Val loss: 1.649 | Gen: edway away-ay ontay-ertay-enday isway otay-inway\n",
            "Epoch:   4 | Train loss: 1.494 | Val loss: 1.577 | Gen: edway away ontertay-intay isway otay-ingway\n",
            "Epoch:   5 | Train loss: 1.410 | Val loss: 1.518 | Gen: edway away-ayday ontay-interay-ayday isway otay-ingway\n",
            "Epoch:   6 | Train loss: 1.338 | Val loss: 1.468 | Gen: edway aray-ay ontay-interay-ayday isway otay-ingray\n",
            "Epoch:   7 | Train loss: 1.268 | Val loss: 1.462 | Gen: edway arway ongray-ingray-ayday isway otay-ingray\n",
            "Epoch:   8 | Train loss: 1.221 | Val loss: 1.388 | Gen: etway arway ongray-ontay-inway isway otay-ingray\n",
            "Epoch:   9 | Train loss: 1.164 | Val loss: 1.374 | Gen: etway away-awlay ongeray-otay-onday isway otay-ingway\n",
            "Epoch:  10 | Train loss: 1.124 | Val loss: 1.354 | Gen: etay arway ongertay-onstay isway otay-inway\n",
            "Epoch:  11 | Train loss: 1.068 | Val loss: 1.259 | Gen: ethay arway ontay-intertay isway orlistway\n",
            "Epoch:  12 | Train loss: 1.007 | Val loss: 1.221 | Gen: ethay aidway ongnay-intersay isway ongay-inway\n",
            "Epoch:  13 | Train loss: 0.973 | Val loss: 1.194 | Gen: ethay ailway ontingnay-inway isway orlisgay\n",
            "Epoch:  14 | Train loss: 0.937 | Val loss: 1.183 | Gen: ethay ainway ondengay-othingway isway orlissinay\n",
            "Epoch:  15 | Train loss: 0.910 | Val loss: 1.204 | Gen: etway ainway ontay-interay-anday isway ongay-inway\n",
            "Epoch:  16 | Train loss: 0.898 | Val loss: 1.135 | Gen: etsay ailway ondingcay-inway isway orgistway\n",
            "Epoch:  17 | Train loss: 0.840 | Val loss: 1.104 | Gen: etsay airway ondingray-onsway isway ormblesway\n",
            "Epoch:  18 | Train loss: 0.799 | Val loss: 1.057 | Gen: ethay airway ondingray-otay isway ormingway\n",
            "Epoch:  19 | Train loss: 0.767 | Val loss: 1.035 | Gen: ethay airway ondingnay-incay isway onsiglay\n",
            "Epoch:  20 | Train loss: 0.750 | Val loss: 1.020 | Gen: ethay airway ontinganicilay isway onsigglay\n",
            "Epoch:  21 | Train loss: 0.720 | Val loss: 0.990 | Gen: ethay airway ontinalingnay isway onsiglay\n",
            "Epoch:  22 | Train loss: 0.690 | Val loss: 1.006 | Gen: ethay airway ontingray-onday isway onsiggray\n",
            "Epoch:  23 | Train loss: 0.666 | Val loss: 0.983 | Gen: ethay airway ontingnalingay isway onsigglay\n",
            "Epoch:  24 | Train loss: 0.647 | Val loss: 0.950 | Gen: ethay airway ontinay-othinday isway onsiggray\n",
            "Epoch:  25 | Train loss: 0.630 | Val loss: 0.935 | Gen: ethay ainway ontingnay-othay isway onsigglay\n",
            "Epoch:  26 | Train loss: 0.622 | Val loss: 0.960 | Gen: ethay airway ontingnay-orday isway onsiggway\n",
            "Epoch:  27 | Train loss: 0.605 | Val loss: 0.927 | Gen: ethay airway ontingnay-othpay isway ormedgeway\n",
            "Epoch:  28 | Train loss: 0.589 | Val loss: 0.931 | Gen: ethay ainway ontingnalipay isway orkingway\n",
            "Epoch:  29 | Train loss: 0.572 | Val loss: 0.962 | Gen: etay airway ontingnarmay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.573 | Val loss: 0.896 | Gen: ethay ainway ontinaliongay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.545 | Val loss: 0.875 | Gen: ethay airway ontingnay-ortmay isway orkingway\n",
            "Epoch:  32 | Train loss: 0.521 | Val loss: 0.837 | Gen: ethay airway oningray-othay isway orkingway\n",
            "Epoch:  33 | Train loss: 0.505 | Val loss: 0.845 | Gen: ethay ainway oningranicay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.495 | Val loss: 0.844 | Gen: ethay ainway ontingnay-othay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.485 | Val loss: 0.838 | Gen: ethay airway ontingnalidcay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.486 | Val loss: 0.853 | Gen: ethay airway ontingnalionay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.507 | Val loss: 0.907 | Gen: ethay airway oningnalinay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.504 | Val loss: 0.847 | Gen: ethay airway oningray-othedmay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.471 | Val loss: 0.841 | Gen: ethay airway ontingranglay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.454 | Val loss: 0.787 | Gen: ethay airway onintaliongay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.444 | Val loss: 0.817 | Gen: ethay airway ontingdermaycay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.445 | Val loss: 0.830 | Gen: ethay airway ondingnalionay isway ormighway\n",
            "Epoch:  43 | Train loss: 0.427 | Val loss: 0.765 | Gen: ethay airway oningrationcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.410 | Val loss: 0.779 | Gen: ethay airway oningrationcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.395 | Val loss: 0.778 | Gen: ethay airway onintaliongay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.387 | Val loss: 0.772 | Gen: ethay airway oningrationcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.377 | Val loss: 0.753 | Gen: ethay airway onintalingday isway orkingway\n",
            "Epoch:  48 | Train loss: 0.371 | Val loss: 0.764 | Gen: ethay airway ondintioficaray isway orkingway\n",
            "Epoch:  49 | Train loss: 0.365 | Val loss: 0.797 | Gen: ethay airway onintedilicay isway orkingway\n",
            "Obtained lowest validation loss of: 0.7528372138308791\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onintedilicay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01HsZ6EItc56"
      },
      "source": [
        "The code below plots the training and validation losses of each model, as a function of the number of gradient descent iterations. Consider if there are significant differences in the validation performance of each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Qyk_9-Fwtekj",
        "outputId": "526199ce-38f5-4de7-9f1a-930fec2e895a"
      },
      "source": [
        "save_loss_comparison_lstm(rnn_losses_s, rnn_losses_l, rnn_args_s, rnn_args_l, 'lstm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE4ijaCzneAt"
      },
      "source": [
        "Select best performing model, and try translating different sentences by changing the variable TEST_SENTENCE. Identify a failure mode and briefly describe it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrNnz8W1nULf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497ec293-879b-42d4-b664-817de94c41ce"
      },
      "source": [
        "best_encoder = rnn_encode_s # Replace with rnn_losses_s or rnn_losses l\n",
        "best_decoder = rnn_decoder_s # etc.\n",
        "best_args = rnn_args_s\n",
        "\n",
        "TEST_SENTENCE = 'his son is an eight-year-old student'\n",
        "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "print(\"correct:\\tishay onsay isway anway eightway-earyay-oldway udentstay\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\this son is an eight-year-old student \n",
            "translated:\tishay onsay isway anway erifatingtingway udtstay\n",
            "correct:\tishay onsay isway anway eightway-earyay-oldway udentstay\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPHsN_uzTY4l",
        "outputId": "5caaef00-53a5-4405-f2f1-564002c46556"
      },
      "source": [
        "# other test cases\n",
        "TEST_SENTENCE = 'the model with smaller dataset performs significantly better'\n",
        "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "print(\"correct:\\tethay odelmay ithway allersmay atasetday erformsay ignificantlysay etterbay\\n\")\n",
        "\n",
        "TEST_SENTENCE = 'people are facing a severe situation of resources shortage and environmental pollution and degradation of ecosystems'\n",
        "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "print(\"correct:\\teoplepay areway acingfay away everesay ituationsay ofay esourcesray ortageshay andway environmentalway ollutionpay andway egradationday ofway ecosystemsway\\n\")\n",
        "\n",
        "TEST_SENTENCE = 'turning off the lights when leaving is not common'\n",
        "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "print(\"correct:\\turningtay offway ethay ightslay enwhay eavinglay isway otnay ommoncay\\n\")\n",
        "\n",
        "TEST_SENTENCE = 'there are many other ways to achieve a low-carbon lifestyle'\n",
        "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))\n",
        "print(\"correct:\\terethay areway anymay otherway aysway otay achieveay away owlay-arboncay ifestylelay\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tthe model with smaller dataset performs significantly better \n",
            "translated:\tehtay omedway ithway alluatleway atatisgay erfomstray ighhirgsay-inway etterwhay\n",
            "correct:\tethay odelmay ithway allersmay atasetday erformsay ignificantlysay etterbay\n",
            "\n",
            "source:\t\tpeople are facing a severe situation of resources shortage and environmental pollution and degradation of ecosystems \n",
            "translated:\tepolpoway arway acgingway away eeversay istblay-ompraway ofay eroussercay orreathray andway endimepray-ousedway olluthoryjay andway erfaghtaddnay ofay essionstay\n",
            "correct:\teoplepay areway acingfay away everesay ituationsay ofay esourcesray ortageshay andway environmentalway ollutionpay andway egradationday ofway ecosystemsway\n",
            "\n",
            "source:\t\tturning off the lights when leaving is not common \n",
            "translated:\tundingray fffay ehtay ightray entway ealigureway isway otay ommoncay\n",
            "correct:\turningtay offway ethay ightslay enwhay eavinglay isway otnay ommoncay\n",
            "\n",
            "source:\t\tthere are many other ways to achieve a low-carbon lifestyle \n",
            "translated:\terethay arway ayfay ortheway aysay otay awivenceway away oudcatcray ifellyseray\n",
            "correct:\terethay areway anymay otherway aysway otay achieveay away owlay-arboncay ifestylelay\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWwA6OGqlaTq"
      },
      "source": [
        "# Part 2: Additive Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJSafHSAmu_w"
      },
      "source": [
        "## Step 1: Additive Attention\n",
        "Already implemented the additive attention mechanism. Write down the mathematical expression for $\\tilde{\\alpha}_i^{(t)}, \\alpha_i^{(t)}, c_t$ as a function of $W_1, W_2, b_1, b_2, Q_t, K_i$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdewEVSMo5jJ"
      },
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # A two layer fully-connected network\n",
        "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
        "        self.attention_network = nn.Sequential(\n",
        "                                    nn.Linear(hidden_size*2, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(hidden_size, 1)\n",
        "                                 )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the additive attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "        batch_size = keys.size(0)\n",
        "        expanded_queries = queries.view(batch_size, -1, self.hidden_size).expand_as(keys)\n",
        "        concat_inputs = torch.cat([expanded_queries, keys], dim=2)\n",
        "        unnormalized_attention = self.attention_network(concat_inputs)\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(attention_weights.transpose(2,1), values)\n",
        "        return context, attention_weights\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73_p8d5EmvOJ"
      },
      "source": [
        "## Step 2: RNN Additive Attention Decoder\n",
        "We will now implement a recurrent decoder that makes use of the additive attention mechanism. Read the description in the assignment worksheet and complete the following implementation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJaABkXrpJSw"
      },
      "source": [
        "class RNNAttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, attention_type='scaled_dot'):\n",
        "        super(RNNAttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        self.rnn = MyLSTMCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
        "        if attention_type == 'additive':\n",
        "          self.attention = AdditiveAttention(hidden_size=hidden_size)\n",
        "        elif attention_type == 'scaled_dot':\n",
        "          self.attention = ScaledDotAttention(hidden_size=hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
        "            cell_init: The final cell states from the encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        attentions = []\n",
        "        h_prev = hidden_init\n",
        "        c_prev = cell_init\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            embed_current = embed[:,i,:]  # Get the current time step, across the whole batch\n",
        "            context, attention_weights = self.attention(h_prev, annotations, annotations)  # batch_size x 1 x hidden_size\n",
        "            embed_and_context = torch.cat([embed_current, context.squeeze(1)], dim=1)  # batch_size x (2*hidden_size)\n",
        "            h_prev, c_prev = self.rnn(embed_and_context, h_prev, c_prev)  # batch_size x hidden_size            \n",
        "            \n",
        "            \n",
        "            hiddens.append(h_prev)\n",
        "            attentions.append(attention_weights)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, attentions\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYPae08Io1Fi"
      },
      "source": [
        "## Step 3: Training and Analysis\n",
        "Train the following language model that uses a recurrent encoder, and a recurrent decoder that has an additive attention component. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke6t6rCezpZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93309b8a-93f4-4605-f588-6ea5fd653cba"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "rnn_attn_args = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_small',\n",
        "              'cuda':True, \n",
        "              'nepochs':50, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005,\n",
        "              'lr_decay':0.99,\n",
        "              'early_stopping_patience':10,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':64, \n",
        "              'encoder_type': 'rnn', # options: rnn / transformer\n",
        "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': 'additive',  # options: additive / scaled_dot\n",
        "}\n",
        "rnn_attn_args.update(args_dict)\n",
        "\n",
        "print_opts(rnn_attn_args)\n",
        "rnn_attn_encoder, rnn_attn_decoder, rnn_attn_losses = train(rnn_attn_args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_small                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 50                                     \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                early_stopping_patience: 10                                     \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 64                                     \n",
            "                           encoder_type: rnn                                    \n",
            "                           decoder_type: rnn_attention                          \n",
            "                         attention_type: additive                               \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('inheritor', 'inheritorway')\n",
            "('schemes', 'emesschay')\n",
            "('bathed', 'athedbay')\n",
            "('audacity', 'audacityway')\n",
            "('significant', 'ignificantsay')\n",
            "Num unique word pairs: 3198\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.065 | Val loss: 1.903 | Gen: etay ilway ontintay-etay ilway ontay-ontay\n",
            "Epoch:   1 | Train loss: 1.569 | Val loss: 1.736 | Gen: etay ilway-ay-ay-ay-ay-ay illsay-ondtay-intay isway osay-omay-otay\n",
            "Epoch:   2 | Train loss: 1.307 | Val loss: 1.563 | Gen: etay away-atedway intingtingay isway ontay-ontay\n",
            "Epoch:   3 | Train loss: 1.104 | Val loss: 1.399 | Gen: etay arway ingsingdingway isway ingway-ingway\n",
            "Epoch:   4 | Train loss: 0.952 | Val loss: 1.331 | Gen: etay arway ondingway-indtay isway orway-ingway\n",
            "Epoch:   5 | Train loss: 0.819 | Val loss: 1.096 | Gen: ethay arway-awlay onincingway-inghay isway orfingway\n",
            "Epoch:   6 | Train loss: 0.694 | Val loss: 1.035 | Gen: ethay ariway ondingingay isway oday-inghay\n",
            "Epoch:   7 | Train loss: 0.582 | Val loss: 0.966 | Gen: etay away-arhay onindingcay isway orway-inghay\n",
            "Epoch:   8 | Train loss: 0.494 | Val loss: 0.872 | Gen: eteway airway ondindcay-ingray isway ordingway\n",
            "Epoch:   9 | Train loss: 0.444 | Val loss: 0.824 | Gen: ethay ariway ondingcionay isway ordway-ingray\n",
            "Epoch:  10 | Train loss: 0.374 | Val loss: 0.711 | Gen: eetway ariway ondingionsay issay ordway-ingway\n",
            "Epoch:  11 | Train loss: 0.301 | Val loss: 0.644 | Gen: ehtay airway ondiondifingcay isway ordingway\n",
            "Epoch:  12 | Train loss: 0.245 | Val loss: 0.579 | Gen: ethay airway ondingionday isway orkingway\n",
            "Epoch:  13 | Train loss: 0.177 | Val loss: 0.581 | Gen: ethay airay ondingiondcay isway orkingway\n",
            "Epoch:  14 | Train loss: 0.151 | Val loss: 0.482 | Gen: ethay airway ondingionday isway oksingwray\n",
            "Epoch:  15 | Train loss: 0.121 | Val loss: 0.430 | Gen: ethay airay ondinitingcay isway orkingway\n",
            "Epoch:  16 | Train loss: 0.102 | Val loss: 0.486 | Gen: ethay airay ondingiongcay isway orkingway\n",
            "Epoch:  17 | Train loss: 0.106 | Val loss: 0.517 | Gen: ethay airay ondifingcay isway orkingway\n",
            "Epoch:  18 | Train loss: 0.106 | Val loss: 0.454 | Gen: ethay airway ondionitingcay isway orkingway\n",
            "Epoch:  19 | Train loss: 0.110 | Val loss: 0.404 | Gen: ettay airway onditionusingcay isway orkingway\n",
            "Epoch:  20 | Train loss: 0.100 | Val loss: 0.373 | Gen: ethay airay onditioningcay isway orkingway\n",
            "Epoch:  21 | Train loss: 0.055 | Val loss: 0.300 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  22 | Train loss: 0.047 | Val loss: 0.289 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  23 | Train loss: 0.042 | Val loss: 0.289 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  24 | Train loss: 0.034 | Val loss: 0.268 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  25 | Train loss: 0.036 | Val loss: 0.408 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  26 | Train loss: 0.063 | Val loss: 0.312 | Gen: ethay airway onditionulingay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.062 | Val loss: 0.481 | Gen: ethay airway onditiondingway issay orkingway\n",
            "Epoch:  28 | Train loss: 0.098 | Val loss: 0.523 | Gen: ethay airway onditininetcay isway orkingway\n",
            "Epoch:  29 | Train loss: 0.105 | Val loss: 0.396 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.067 | Val loss: 0.374 | Gen: ethay airway onditiondcay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.065 | Val loss: 0.331 | Gen: ethay airway onditionitusway isway orkingway\n",
            "Epoch:  32 | Train loss: 0.062 | Val loss: 0.386 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  33 | Train loss: 0.057 | Val loss: 0.273 | Gen: ethay airway onditingioncay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.025 | Val loss: 0.243 | Gen: ethay airway onditionitercay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.014 | Val loss: 0.219 | Gen: ethay airway onditionitincay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.008 | Val loss: 0.211 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.006 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.005 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.004 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.004 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.003 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.003 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.003 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.003 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.002 | Val loss: 0.209 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.002 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.002 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.002 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  49 | Train loss: 0.002 | Val loss: 0.210 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Obtained lowest validation loss of: 0.2094228501940961\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNVKbLc0ACj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db154b9-56ce-4e0f-bb13-259fcd5f092e"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw_GOIvzo1ix"
      },
      "source": [
        "# Part 3: Scaled Dot Product Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq7nhsEio1w-"
      },
      "source": [
        "## Step 1: Implement Dot-Product Attention\n",
        "Implement the scaled dot product attention module described in the assignment worksheet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_j3oY3hqsJQ"
      },
      "source": [
        "class ScaledDotAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(ScaledDotAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
        "        self.K = nn.Linear(hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, hidden_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x k x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The output must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        batch_size = queries.size()[0]\n",
        "        # 2D to 3D\n",
        "        if len(queries.size()) == 2:\n",
        "          queries = queries.view(batch_size, 1, self.hidden_size)\n",
        "        q = self.Q(queries)\n",
        "        k = self.K(keys)\n",
        "        v = self.V(values)\n",
        "        # print(\"dimension: queries-{}\\nkeys-{}\\nq-{}\\nk-{}\\nv-{}\\n\".format(queries.size(), keys.size(), q.size(), k.size(), v.size()))\n",
        "        unnormalized_attention = torch.bmm(k, torch.transpose(q, 1, 2)) * self.scaling_factor\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(torch.transpose(attention_weights, 1, 2), v)\n",
        "        return context, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unReAOrjo113"
      },
      "source": [
        "## Step 2: Implement Causal Dot-Product Attention\n",
        "Now implement the scaled causal dot product described in the assignment worksheet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovigzQffrKqj"
      },
      "source": [
        "class CausalScaledDotAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(CausalScaledDotAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.neg_inf = torch.tensor(-1e7)\n",
        "\n",
        "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
        "        self.K = nn.Linear(hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, hidden_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x k x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The output must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        batch_size = queries.size()[0]\n",
        "        # 2D to 3D\n",
        "        if len(queries.size()) == 2:\n",
        "          queries = queries.view(batch_size, 1, self.hidden_size)\n",
        "        q = self.Q(queries)\n",
        "        k = self.K(keys)\n",
        "        v = self.V(values)\n",
        "        unnormalized_attention = torch.bmm(k, torch.transpose(q, 1, 2)) * self.scaling_factor\n",
        "        mask = torch.tril(torch.ones_like(unnormalized_attention) * self.neg_inf, diagonal=-1)\n",
        "        # print(mask)\n",
        "        attention_weights = self.softmax(torch.triu(unnormalized_attention) + mask)\n",
        "        context = torch.bmm(torch.transpose(attention_weights, 1, 2), v)\n",
        "        return context, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tcpUFKqo2Oi"
      },
      "source": [
        "## Step 3: Transformer Encoder\n",
        "Complete the following transformer encoder implementation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3B-fWsarlVk"
      },
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, opts):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.opts = opts\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        \n",
        "        self.self_attentions = nn.ModuleList([ScaledDotAttention(\n",
        "                                    hidden_size=hidden_size, \n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
        "                                    nn.Linear(hidden_size, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                 ) for i in range(self.num_layers)])\n",
        "\n",
        "        self.positional_encodings = self.create_positional_encodings()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass of the encoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
        "\n",
        "        Returns:\n",
        "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            None: Used to conform to standard encoder return signature.\n",
        "            None: Used to conform to standard encoder return signature.        \n",
        "        \"\"\"\n",
        "        batch_size, seq_len = inputs.size()\n",
        "\n",
        "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "\n",
        "        # Add positinal embeddings from self.create_positional_encodings. (a'la https://arxiv.org/pdf/1706.03762.pdf, section 3.5)\n",
        "        encoded = encoded + self.positional_encodings[:seq_len]\n",
        "\n",
        "        annotations = encoded\n",
        "        for i in range(self.num_layers):\n",
        "            new_annotations, self_attention_weights = self.self_attentions[i](annotations, annotations, annotations)  # batch_size x seq_len x hidden_size\n",
        "            residual_annotations = annotations + new_annotations\n",
        "            new_annotations = self.attention_mlps[i](residual_annotations)\n",
        "            annotations = residual_annotations + new_annotations\n",
        "\n",
        "        # Transformer encoder does not have a last hidden or cell layer. \n",
        "        return annotations, None, None\n",
        "\n",
        "    def create_positional_encodings(self, max_seq_len=1000):\n",
        "        \"\"\"Creates positional encodings for the inputs.\n",
        "\n",
        "        Arguments:\n",
        "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
        "\n",
        "        Returns:\n",
        "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
        "        \"\"\"\n",
        "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
        "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
        "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
        "        trig_args = pos_indices / (10000**exponents)\n",
        "        sin_terms = torch.sin(trig_args)\n",
        "        cos_terms = torch.cos(trig_args)\n",
        "\n",
        "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
        "        pos_encodings[:, 0::2] = sin_terms\n",
        "        pos_encodings[:, 1::2] = cos_terms\n",
        "\n",
        "        if self.opts.cuda:\n",
        "            pos_encodings = pos_encodings.cuda()\n",
        "\n",
        "        return pos_encodings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1hDi020rT36"
      },
      "source": [
        "## Step 4: Transformer Decoder\n",
        "Complete the following transformer decoder implementation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyvTZFxtrvc6"
      },
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)        \n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.self_attentions = nn.ModuleList([CausalScaledDotAttention(\n",
        "                                    hidden_size=hidden_size, \n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.encoder_attentions = nn.ModuleList([ScaledDotAttention(\n",
        "                                    hidden_size=hidden_size, \n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
        "                                    nn.Linear(hidden_size, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        self.positional_encodings = self.create_positional_encodings()\n",
        "\n",
        "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: Not used in the transformer decoder\n",
        "            cell_init: Not used in transformer decoder\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "\n",
        "        embed = embed + self.positional_encodings[:seq_len]\n",
        "\n",
        "        encoder_attention_weights_list = []\n",
        "        self_attention_weights_list = []\n",
        "        contexts = embed\n",
        "        for i in range(self.num_layers):\n",
        "            new_contexts, self_attention_weights = self.self_attentions[i](contexts, contexts, contexts)  # batch_size x seq_len x hidden_size\n",
        "            residual_contexts = contexts + new_contexts\n",
        "            new_contexts, encoder_attention_weights = self.encoder_attentions[i](residual_contexts, annotations, annotations) # batch_size x seq_len x hidden_size\n",
        "            residual_contexts = residual_contexts + new_contexts\n",
        "            new_contexts = self.attention_mlps[i](residual_contexts)\n",
        "            contexts = residual_contexts + new_contexts\n",
        "\n",
        "            encoder_attention_weights_list.append(encoder_attention_weights)\n",
        "            self_attention_weights_list.append(self_attention_weights)\n",
        "          \n",
        "        output = self.out(contexts)\n",
        "        encoder_attention_weights = torch.stack(encoder_attention_weights_list)\n",
        "        self_attention_weights = torch.stack(self_attention_weights_list)\n",
        "        \n",
        "        return output, (encoder_attention_weights, self_attention_weights)\n",
        "\n",
        "    def create_positional_encodings(self, max_seq_len=1000):\n",
        "        \"\"\"Creates positional encodings for the inputs.\n",
        "\n",
        "        Arguments:\n",
        "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
        "\n",
        "        Returns:\n",
        "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
        "        \"\"\"\n",
        "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
        "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
        "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
        "        trig_args = pos_indices / (10000**exponents)\n",
        "        sin_terms = torch.sin(trig_args)\n",
        "        cos_terms = torch.cos(trig_args)\n",
        "\n",
        "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
        "        pos_encodings[:, 0::2] = sin_terms\n",
        "        pos_encodings[:, 1::2] = cos_terms\n",
        "\n",
        "        pos_encodings = pos_encodings.cuda()\n",
        "\n",
        "        return pos_encodings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ZjkXTNrUKb"
      },
      "source": [
        "\n",
        "## Step 5: Training and analysis\n",
        "Now, train the following language model that's comprised of a (simplified) transformer encoder and transformer decoder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqTp-eCPuuFO"
      },
      "source": [
        "First, we train our smaller model on the small dataset. Use this model to answer Question 4 in the handout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk8e4KSnuZ8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c919077b-eef5-49e0-b122-952cfa3d70bc"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "trans32_args_s = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_small',\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':5e-4,\n",
        "              'early_stopping_patience': 100,\n",
        "              'lr_decay':0.99,\n",
        "              'batch_size': 64,\n",
        "              'hidden_size': 32,\n",
        "              'encoder_type': 'transformer',\n",
        "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
        "              'num_transformer_layers': 3,\n",
        "}\n",
        "trans32_args_s.update(args_dict)\n",
        "print_opts(trans32_args_s)\n",
        "\n",
        "trans32_encoder_s, trans32_decoder_s, trans32_losses_s = train(trans32_args_s)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_small                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.0005                                 \n",
            "                early_stopping_patience: 100                                    \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 32                                     \n",
            "                           encoder_type: transformer                            \n",
            "                           decoder_type: transformer                            \n",
            "                 num_transformer_layers: 3                                      \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('inheritor', 'inheritorway')\n",
            "('schemes', 'emesschay')\n",
            "('bathed', 'athedbay')\n",
            "('audacity', 'audacityway')\n",
            "('significant', 'ignificantsay')\n",
            "Num unique word pairs: 3198\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.696 | Val loss: 2.329 | Gen: eay ay-ay-ay ioiowioway ay onoway\n",
            "Epoch:   1 | Train loss: 2.053 | Val loss: 2.043 | Gen: eay-ay-eay ay-iay-ay-ay-iay-ay- ooonionionionionioni isssay ionioway-iononionine\n",
            "Epoch:   2 | Train loss: 1.803 | Val loss: 1.858 | Gen: eay ay-iay-ay-ay ontioniononionionion isay onionioneway-ioninay\n",
            "Epoch:   3 | Train loss: 1.625 | Val loss: 1.735 | Gen: etay ay otionioncay isay ongfiongfway\n",
            "Epoch:   4 | Train loss: 1.489 | Val loss: 1.641 | Gen: ay alway ongffffffffionioncay isay ongfway-ongfway\n",
            "Epoch:   5 | Train loss: 1.381 | Val loss: 1.626 | Gen: tay alway ontintintionionininc isssay ongway-ongway\n",
            "Epoch:   6 | Train loss: 1.293 | Val loss: 1.537 | Gen: ewtay away ontingntinionininini issay ongringway\n",
            "Epoch:   7 | Train loss: 1.210 | Val loss: 1.514 | Gen: etay away ontintingay issay ongray-ongway\n",
            "Epoch:   8 | Train loss: 1.158 | Val loss: 1.500 | Gen: ewtay away ontintingay issay ongray-oray\n",
            "Epoch:   9 | Train loss: 1.122 | Val loss: 1.525 | Gen: eththay away-away ontingctionionctinca isay ongringpgway\n",
            "Epoch:  10 | Train loss: 1.080 | Val loss: 1.650 | Gen: eway-thway away onctintingnay sway ongray-orway\n",
            "Epoch:  11 | Train loss: 1.112 | Val loss: 1.415 | Gen: ethay away-ay onctiongay isssay oringray-ongrway\n",
            "Epoch:  12 | Train loss: 0.995 | Val loss: 1.333 | Gen: ethay-ay away-ay-ay onctiongay isway oringray-ongrway\n",
            "Epoch:  13 | Train loss: 0.931 | Val loss: 1.336 | Gen: eay-ay-thway awayway oncininicay isway oringray-ongrway-ay\n",
            "Epoch:  14 | Train loss: 0.891 | Val loss: 1.300 | Gen: ehway-ththway awayway onctiongay isway oringway-orway\n",
            "Epoch:  15 | Train loss: 0.857 | Val loss: 1.343 | Gen: eay-thway awayway onctingcay isway oringway-oway\n",
            "Epoch:  16 | Train loss: 0.830 | Val loss: 1.281 | Gen: ehtway awaywayway onctiontionionictini isway oringway-oway\n",
            "Epoch:  17 | Train loss: 0.806 | Val loss: 1.278 | Gen: ehway-thway awayway onditingcay isway oringway-oway\n",
            "Epoch:  18 | Train loss: 0.764 | Val loss: 1.266 | Gen: ehwtway awaywayway onditingctay isway oringway-oway\n",
            "Epoch:  19 | Train loss: 0.741 | Val loss: 1.307 | Gen: ehway awayway onditingctioningdway isway oringway-oway\n",
            "Epoch:  20 | Train loss: 0.729 | Val loss: 1.268 | Gen: ehthtway ariway onditingctay isway oringway-oway\n",
            "Epoch:  21 | Train loss: 0.700 | Val loss: 1.229 | Gen: ehthway arway-iway onditingttiongcty-on isway oingrrway\n",
            "Epoch:  22 | Train loss: 0.679 | Val loss: 1.187 | Gen: ehwtway iwaraway onditingctiongday isway oringway\n",
            "Epoch:  23 | Train loss: 0.676 | Val loss: 1.167 | Gen: ehwtway arwayway onditingctionisinisc isway oringway\n",
            "Epoch:  24 | Train loss: 0.644 | Val loss: 1.116 | Gen: ehwtway arwayway onditingctioningday isway oringway-ongway\n",
            "Epoch:  25 | Train loss: 0.606 | Val loss: 1.086 | Gen: ehway awaway onditingctiongday isway oringway\n",
            "Epoch:  26 | Train loss: 0.587 | Val loss: 1.048 | Gen: ehwtway ariway onditingctionisay isway oringway\n",
            "Epoch:  27 | Train loss: 0.567 | Val loss: 1.074 | Gen: ehway-thway awawayway onditingctiongday isway oringway\n",
            "Epoch:  28 | Train loss: 0.551 | Val loss: 1.048 | Gen: ehwtway awaway onditingctiongday isway oringway\n",
            "Epoch:  29 | Train loss: 0.530 | Val loss: 1.060 | Gen: ehway awaway onditingctiongday isway oringway\n",
            "Epoch:  30 | Train loss: 0.511 | Val loss: 1.011 | Gen: ehway awaway onditingctiongday isway oringway\n",
            "Epoch:  31 | Train loss: 0.491 | Val loss: 1.013 | Gen: ehway awaway onditingctiongday isway oringway\n",
            "Epoch:  32 | Train loss: 0.481 | Val loss: 0.985 | Gen: ehway ariway onditiongcay isway oringway\n",
            "Epoch:  33 | Train loss: 0.468 | Val loss: 0.992 | Gen: ehway awayway onditingcay isway oringway\n",
            "Epoch:  34 | Train loss: 0.487 | Val loss: 1.027 | Gen: ehthway awayway onditiongday iswayyyyyyy oringway\n",
            "Epoch:  35 | Train loss: 0.546 | Val loss: 1.034 | Gen: ehwtway iwarway onditingday isway oringway\n",
            "Epoch:  36 | Train loss: 0.537 | Val loss: 1.119 | Gen: ehway iwarway onditisiciongicay isway oringway\n",
            "Epoch:  37 | Train loss: 0.520 | Val loss: 1.055 | Gen: ehay-ay awayway ondintiongday isway oringway\n",
            "Epoch:  38 | Train loss: 0.442 | Val loss: 0.941 | Gen: ehathway awayway onditingcay isway oringway\n",
            "Epoch:  39 | Train loss: 0.410 | Val loss: 0.954 | Gen: ehatway awayway onditingcay isway oringway\n",
            "Epoch:  40 | Train loss: 0.394 | Val loss: 0.933 | Gen: ehathway awayway onditingcay isway oringway\n",
            "Epoch:  41 | Train loss: 0.380 | Val loss: 0.924 | Gen: ehathway awayway onditiongcay isway oringway\n",
            "Epoch:  42 | Train loss: 0.369 | Val loss: 0.925 | Gen: ehathway awayway onditiongcay isway oringway\n",
            "Epoch:  43 | Train loss: 0.358 | Val loss: 0.921 | Gen: ehathway awayway onditiongcay isway oringway\n",
            "Epoch:  44 | Train loss: 0.349 | Val loss: 0.920 | Gen: ehtway awayway onditiongcay isway oringway\n",
            "Epoch:  45 | Train loss: 0.340 | Val loss: 0.926 | Gen: ehtway awayway onditiongcay isway oringway\n",
            "Epoch:  46 | Train loss: 0.333 | Val loss: 0.931 | Gen: ehtway awayway onditiongcay isway oringway\n",
            "Epoch:  47 | Train loss: 0.346 | Val loss: 0.992 | Gen: ehatway awayway onditiongday isway oringway\n",
            "Epoch:  48 | Train loss: 0.347 | Val loss: 0.947 | Gen: ehtay awayway onditiongcay isway oringway\n",
            "Epoch:  49 | Train loss: 0.323 | Val loss: 0.873 | Gen: ethay awayway onditingcay isway oringway\n",
            "Epoch:  50 | Train loss: 0.304 | Val loss: 0.878 | Gen: ehtway away onditiongcay isway oringway\n",
            "Epoch:  51 | Train loss: 0.297 | Val loss: 0.878 | Gen: ehtway awayway onditiongday isway oringway\n",
            "Epoch:  52 | Train loss: 0.288 | Val loss: 0.869 | Gen: ethay away onditiongcay isway oringway\n",
            "Epoch:  53 | Train loss: 0.281 | Val loss: 0.893 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  54 | Train loss: 0.274 | Val loss: 0.866 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  55 | Train loss: 0.268 | Val loss: 0.876 | Gen: ethay awaway onditiongcay isway oringway\n",
            "Epoch:  56 | Train loss: 0.262 | Val loss: 0.858 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  57 | Train loss: 0.257 | Val loss: 0.880 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  58 | Train loss: 0.251 | Val loss: 0.864 | Gen: ethay awaway onditiongcay isway oringway\n",
            "Epoch:  59 | Train loss: 0.247 | Val loss: 0.872 | Gen: ethay awaway onditiongcay isway oringway\n",
            "Epoch:  60 | Train loss: 0.241 | Val loss: 0.845 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  61 | Train loss: 0.237 | Val loss: 0.897 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  62 | Train loss: 0.231 | Val loss: 0.851 | Gen: ethay awaway onditiongcay isway oringway\n",
            "Epoch:  63 | Train loss: 0.228 | Val loss: 0.921 | Gen: ethay awaway onditiongdcay isway oringway\n",
            "Epoch:  64 | Train loss: 0.285 | Val loss: 1.080 | Gen: ehehway awiway onditionionindcincin isway oringway\n",
            "Epoch:  65 | Train loss: 0.422 | Val loss: 1.024 | Gen: ethway iwayway onditionionicy isway iringway\n",
            "Epoch:  66 | Train loss: 0.378 | Val loss: 0.797 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  67 | Train loss: 0.266 | Val loss: 0.788 | Gen: ethay away onditingcay isway oringway\n",
            "Epoch:  68 | Train loss: 0.237 | Val loss: 0.778 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  69 | Train loss: 0.223 | Val loss: 0.793 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  70 | Train loss: 0.213 | Val loss: 0.779 | Gen: ethay awayway onditiongcay isway oringway\n",
            "Epoch:  71 | Train loss: 0.207 | Val loss: 0.787 | Gen: ethay awayway onditiongcay isway oringngway\n",
            "Epoch:  72 | Train loss: 0.202 | Val loss: 0.794 | Gen: ehtay awayway onditiongcay isway oringngway\n",
            "Epoch:  73 | Train loss: 0.197 | Val loss: 0.801 | Gen: ehtay awayway ondictiongway isway oringngway\n",
            "Epoch:  74 | Train loss: 0.194 | Val loss: 0.808 | Gen: ehtay awayway ondictiongngway isway oringngway\n",
            "Epoch:  75 | Train loss: 0.190 | Val loss: 0.814 | Gen: ehtway awayway ondictiongngway isway oringngway\n",
            "Epoch:  76 | Train loss: 0.186 | Val loss: 0.820 | Gen: ehtway awayway ondictiongngway isway oringngway\n",
            "Epoch:  77 | Train loss: 0.183 | Val loss: 0.826 | Gen: ehtway awayway ondictiongngway isway oringngway\n",
            "Epoch:  78 | Train loss: 0.180 | Val loss: 0.831 | Gen: ehtway awayway ondictiongngway isway oringngway\n",
            "Epoch:  79 | Train loss: 0.176 | Val loss: 0.835 | Gen: ehtway awayway ondictiongngway isway oringngway\n",
            "Epoch:  80 | Train loss: 0.173 | Val loss: 0.839 | Gen: ehtway awarway ondictiongngway isway oringngway\n",
            "Epoch:  81 | Train loss: 0.170 | Val loss: 0.845 | Gen: ehtway awarway ondictiongngway isway oringngway\n",
            "Epoch:  82 | Train loss: 0.167 | Val loss: 0.850 | Gen: ehtway awarway ondictiongngway isway oringngway\n",
            "Epoch:  83 | Train loss: 0.163 | Val loss: 0.854 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  84 | Train loss: 0.160 | Val loss: 0.857 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  85 | Train loss: 0.157 | Val loss: 0.860 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  86 | Train loss: 0.154 | Val loss: 0.863 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  87 | Train loss: 0.150 | Val loss: 0.863 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  88 | Train loss: 0.147 | Val loss: 0.866 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  89 | Train loss: 0.144 | Val loss: 0.868 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  90 | Train loss: 0.141 | Val loss: 0.870 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  91 | Train loss: 0.137 | Val loss: 0.871 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  92 | Train loss: 0.134 | Val loss: 0.871 | Gen: ethay awarway ondictiongngway isway oringngway\n",
            "Epoch:  93 | Train loss: 0.131 | Val loss: 0.871 | Gen: ethay awarway onditingcay isway oringngway\n",
            "Epoch:  94 | Train loss: 0.128 | Val loss: 0.878 | Gen: ethay awarway onditingcay isway oringngway\n",
            "Epoch:  95 | Train loss: 0.125 | Val loss: 0.875 | Gen: ethay awarway onditingcay isway oringngway\n",
            "Epoch:  96 | Train loss: 0.122 | Val loss: 0.889 | Gen: ethay awarway onditingcay isway oringngway\n",
            "Epoch:  97 | Train loss: 0.120 | Val loss: 0.879 | Gen: ethay awarway onditingcay isway oringngway\n",
            "Epoch:  98 | Train loss: 0.118 | Val loss: 0.895 | Gen: ethay awayway onditingcray isway oringngway\n",
            "Epoch:  99 | Train loss: 0.117 | Val loss: 0.925 | Gen: ethay awarway onditioningcay isway oringway\n",
            "Obtained lowest validation loss of: 0.7783684799447655\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay awarway onditioningcay isway oringway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l28mKuZxvaRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8b3794-2d2e-4a2d-b599-c4a31585657e"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay awarway onditioningcay isway oringway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L8EqLYFu48H"
      },
      "source": [
        "In the following cells, we investigate the effects of increasing model size and dataset size on the training / validation curves and generalization of the Transformer. We will increase hidden size to 64, and also increase dataset size. Include the best achieved validation loss in your report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdZO69DozuUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3b418c-7d57-4fed-8b29-0bf5ab17449c"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "trans32_args_l = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
        "              'cuda':True, \n",
        "              'nepochs':100,\n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':5e-4,\n",
        "              'early_stopping_patience': 10,\n",
        "              'lr_decay':0.99,\n",
        "              'batch_size': 512,\n",
        "              'hidden_size': 32,\n",
        "              'encoder_type': 'transformer',\n",
        "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
        "              'num_transformer_layers': 3,\n",
        "}\n",
        "trans32_args_l.update(args_dict)\n",
        "print_opts(trans32_args_l)\n",
        "\n",
        "trans32_encoder_l, trans32_decoder_l, trans32_losses_l = train(trans32_args_l)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_l, trans32_decoder_l, None, trans32_args_l)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_large                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.0005                                 \n",
            "                early_stopping_patience: 10                                     \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 512                                    \n",
            "                            hidden_size: 32                                     \n",
            "                           encoder_type: transformer                            \n",
            "                           decoder_type: transformer                            \n",
            "                 num_transformer_layers: 3                                      \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('newcomers', 'ewcomersnay')\n",
            "('lq', 'lqay')\n",
            "('contracting', 'ontractingcay')\n",
            "('garde', 'ardegay')\n",
            "('transexual', 'ansexualtray')\n",
            "Num unique word pairs: 22402\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.731 | Val loss: 2.255 | Gen: y iay iinininininilay y onay\n",
            "Epoch:   1 | Train loss: 2.068 | Val loss: 2.021 | Gen: etttttttty iayay ondndninindndnay isay onuay\n",
            "Epoch:   2 | Train loss: 1.847 | Val loss: 1.875 | Gen: ettttttttttttttttt-a ayray ondndndndndndndnay issssy onurway\n",
            "Epoch:   3 | Train loss: 1.695 | Val loss: 1.744 | Gen: etay aray ondnginingay-onay isssay ongray\n",
            "Epoch:   4 | Train loss: 1.582 | Val loss: 1.672 | Gen: etay-ay aray oningingay-onay isay-ayay ongray\n",
            "Epoch:   5 | Train loss: 1.514 | Val loss: 1.572 | Gen: etay aiay ontongingay-onay isay ongray\n",
            "Epoch:   6 | Train loss: 1.431 | Val loss: 1.542 | Gen: etay iaway oiongingay issy ongray\n",
            "Epoch:   7 | Train loss: 1.353 | Val loss: 1.554 | Gen: etay aray ontingay-inanay isy orgway\n",
            "Epoch:   8 | Train loss: 1.294 | Val loss: 1.432 | Gen: etay iaway oioingingay issay orgway\n",
            "Epoch:   9 | Train loss: 1.240 | Val loss: 1.408 | Gen: etay aray ontintinay-onay isy orgway\n",
            "Epoch:  10 | Train loss: 1.187 | Val loss: 1.361 | Gen: etay iaray oioioininay issay orgway\n",
            "Epoch:  11 | Train loss: 1.131 | Val loss: 1.300 | Gen: ethay araway oooioinioinay isway orginayray\n",
            "Epoch:  12 | Train loss: 1.073 | Val loss: 1.304 | Gen: eway iaray oorioioinay isway orgingay\n",
            "Epoch:  13 | Train loss: 1.034 | Val loss: 1.269 | Gen: ethay iaray onioioinicay isway orgingway\n",
            "Epoch:  14 | Train loss: 1.005 | Val loss: 1.273 | Gen: ehay iaray onitioinicay isway oringway\n",
            "Epoch:  15 | Train loss: 0.981 | Val loss: 1.237 | Gen: etay iaray onitiorinay isay orgingway\n",
            "Epoch:  16 | Train loss: 0.927 | Val loss: 1.268 | Gen: ehay iaray ontitioray isay orgray\n",
            "Epoch:  17 | Train loss: 0.907 | Val loss: 1.209 | Gen: etay aray ontininicay isay orgingway\n",
            "Epoch:  18 | Train loss: 0.893 | Val loss: 1.256 | Gen: ehay aray ontingoray isy orgrgway\n",
            "Epoch:  19 | Train loss: 0.905 | Val loss: 1.147 | Gen: eheway ariay ontiningcay isway orgingway\n",
            "Epoch:  20 | Train loss: 0.839 | Val loss: 1.131 | Gen: ehay-eway araway ontinidicay isy orgingway\n",
            "Epoch:  21 | Train loss: 0.798 | Val loss: 1.095 | Gen: ehay araway ontinidicay isway oringwayway\n",
            "Epoch:  22 | Train loss: 0.783 | Val loss: 1.051 | Gen: ehay-eway arayway ontidioroncay isway orgrgway\n",
            "Epoch:  23 | Train loss: 0.764 | Val loss: 1.095 | Gen: eheway aray ontidioroncay isway oringway\n",
            "Epoch:  24 | Train loss: 0.871 | Val loss: 1.320 | Gen: eheway aiaiayway untitititantiooooona isay orgunglayway\n",
            "Epoch:  25 | Train loss: 0.832 | Val loss: 1.084 | Gen: ehay araway ontioiortincay isay oringway\n",
            "Epoch:  26 | Train loss: 0.736 | Val loss: 1.040 | Gen: eheway aray ontioinicay isay orgingway\n",
            "Epoch:  27 | Train loss: 0.697 | Val loss: 0.977 | Gen: eheway array ontioiordcay isway oringway\n",
            "Epoch:  28 | Train loss: 0.678 | Val loss: 0.959 | Gen: ehay arrway ontioinicepay isway oringway\n",
            "Epoch:  29 | Train loss: 0.649 | Val loss: 0.950 | Gen: eheway ariay ontioioringcay isway oringway\n",
            "Epoch:  30 | Train loss: 0.638 | Val loss: 0.928 | Gen: ehay arrway ontioidingcay isway oringwgway\n",
            "Epoch:  31 | Train loss: 0.605 | Val loss: 0.925 | Gen: eheway ariway ontidiortingcay isway oringwgway\n",
            "Epoch:  32 | Train loss: 0.595 | Val loss: 0.903 | Gen: ehay arrway ontidioringcay isway oringwgway\n",
            "Epoch:  33 | Train loss: 0.580 | Val loss: 0.904 | Gen: eheway ariway ontidioringcay isway oringwgway\n",
            "Epoch:  34 | Train loss: 0.570 | Val loss: 0.884 | Gen: ethay arrway ontididicay isway oringwgway\n",
            "Epoch:  35 | Train loss: 0.550 | Val loss: 0.892 | Gen: ethay ariway ontidioringcay isway oringwgway\n",
            "Epoch:  36 | Train loss: 0.541 | Val loss: 0.869 | Gen: ethay arrway ontididictay isway oringwgway\n",
            "Epoch:  37 | Train loss: 0.525 | Val loss: 0.876 | Gen: ethay ariway ontidioringcay isway oringwgway\n",
            "Epoch:  38 | Train loss: 0.513 | Val loss: 0.859 | Gen: ethay arway ontididictay isway oringwgway\n",
            "Epoch:  39 | Train loss: 0.500 | Val loss: 0.870 | Gen: ethay arrway ontididingcay isway oringwgway\n",
            "Epoch:  40 | Train loss: 0.488 | Val loss: 0.842 | Gen: ethay arway ontididictay isway oringwgway\n",
            "Epoch:  41 | Train loss: 0.475 | Val loss: 0.845 | Gen: ethay arrway ontididingcay isway oringwgway\n",
            "Epoch:  42 | Train loss: 0.464 | Val loss: 0.829 | Gen: ethay arway onditididcay isway oringwgway\n",
            "Epoch:  43 | Train loss: 0.453 | Val loss: 0.826 | Gen: ethay ariway ontididingcay isway oringwgway\n",
            "Epoch:  44 | Train loss: 0.442 | Val loss: 0.805 | Gen: ethay ariway ondiditidcay isway oringwgway\n",
            "Epoch:  45 | Train loss: 0.439 | Val loss: 0.829 | Gen: ethay arrway ontidioingcay isway oringwgway\n",
            "Epoch:  46 | Train loss: 0.429 | Val loss: 0.803 | Gen: ethay arway ondiditiorgcay isway oringway\n",
            "Epoch:  47 | Train loss: 0.467 | Val loss: 0.878 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  48 | Train loss: 0.460 | Val loss: 0.831 | Gen: ethay ariway onditidingcay isway oringwnway\n",
            "Epoch:  49 | Train loss: 0.426 | Val loss: 0.778 | Gen: ethay arway onditioingcay isway oringway\n",
            "Epoch:  50 | Train loss: 0.398 | Val loss: 0.765 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  51 | Train loss: 0.378 | Val loss: 0.772 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  52 | Train loss: 0.369 | Val loss: 0.761 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  53 | Train loss: 0.359 | Val loss: 0.765 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  54 | Train loss: 0.349 | Val loss: 0.757 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  55 | Train loss: 0.343 | Val loss: 0.763 | Gen: ethay arway onditioringcay isway oringway\n",
            "Epoch:  56 | Train loss: 0.335 | Val loss: 0.758 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  57 | Train loss: 0.329 | Val loss: 0.754 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  58 | Train loss: 0.322 | Val loss: 0.756 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  59 | Train loss: 0.318 | Val loss: 0.753 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  60 | Train loss: 0.309 | Val loss: 0.758 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  61 | Train loss: 0.305 | Val loss: 0.779 | Gen: ethay arway onditioringcay isway orringway\n",
            "Epoch:  62 | Train loss: 0.301 | Val loss: 0.749 | Gen: ethay arway onditioringcay isway orringway\n",
            "Epoch:  63 | Train loss: 0.305 | Val loss: 0.779 | Gen: ethay arway onditioingcay isway orringway\n",
            "Epoch:  64 | Train loss: 0.326 | Val loss: 1.024 | Gen: ethay arrway onditingcingway isway orringway\n",
            "Epoch:  65 | Train loss: 0.348 | Val loss: 0.755 | Gen: ethay arway onditioringcay isway orringway\n",
            "Epoch:  66 | Train loss: 0.316 | Val loss: 0.778 | Gen: ethay arway onditioringcay isway orringway\n",
            "Epoch:  67 | Train loss: 0.295 | Val loss: 0.859 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  68 | Train loss: 0.287 | Val loss: 0.728 | Gen: ethay arway onditioringcay isway orringway\n",
            "Epoch:  69 | Train loss: 0.265 | Val loss: 0.724 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  70 | Train loss: 0.255 | Val loss: 0.713 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  71 | Train loss: 0.245 | Val loss: 0.722 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  72 | Train loss: 0.240 | Val loss: 0.721 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  73 | Train loss: 0.233 | Val loss: 0.725 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  74 | Train loss: 0.228 | Val loss: 0.724 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  75 | Train loss: 0.223 | Val loss: 0.722 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  76 | Train loss: 0.217 | Val loss: 0.729 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  77 | Train loss: 0.213 | Val loss: 0.719 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  78 | Train loss: 0.208 | Val loss: 0.723 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  79 | Train loss: 0.204 | Val loss: 0.716 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Epoch:  80 | Train loss: 0.199 | Val loss: 0.722 | Gen: ethay arrway onditioringcay isway orringway\n",
            "Validation loss has not improved in 10 epochs, stopping early\n",
            "Obtained lowest validation loss of: 0.7129870925206118\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay arwway onditioringcay isway orringway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmoTgrDcr_dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f77c5fc-2f1a-4989-9c4d-53e72dee3deb"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "trans64_args_s = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_small',\n",
        "              'cuda':True, \n",
        "              'nepochs':50, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':5e-4,\n",
        "              'early_stopping_patience': 20,\n",
        "              'lr_decay':0.99,\n",
        "              'batch_size': 64, \n",
        "              'hidden_size': 64, # Increased model size\n",
        "              'encoder_type': 'transformer',\n",
        "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
        "              'num_transformer_layers': 3,\n",
        "}\n",
        "trans64_args_s.update(args_dict)\n",
        "print_opts(trans64_args_s)\n",
        "\n",
        "trans64_encoder_s, trans64_decoder_s, trans64_losses_s = train(trans64_args_s)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_s, trans64_decoder_s, None, trans64_args_s)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_small                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 50                                     \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.0005                                 \n",
            "                early_stopping_patience: 20                                     \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 64                                     \n",
            "                           encoder_type: transformer                            \n",
            "                           decoder_type: transformer                            \n",
            "                 num_transformer_layers: 3                                      \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('inheritor', 'inheritorway')\n",
            "('schemes', 'emesschay')\n",
            "('bathed', 'athedbay')\n",
            "('audacity', 'audacityway')\n",
            "('significant', 'ignificantsay')\n",
            "Num unique word pairs: 3198\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.521 | Val loss: 2.112 | Gen: ouway iiiay intatintay-ay issway intay\n",
            "Epoch:   1 | Train loss: 1.722 | Val loss: 1.769 | Gen: eway idway onsay-inway isway oway\n",
            "Epoch:   2 | Train loss: 1.451 | Val loss: 1.538 | Gen: ehay arway onsingangangay isway oway\n",
            "Epoch:   3 | Train loss: 1.269 | Val loss: 1.719 | Gen: eteteteway iraray onsindinddway isway oringway\n",
            "Epoch:   4 | Train loss: 1.154 | Val loss: 1.393 | Gen: ehay iraray oindindday isway oindway\n",
            "Epoch:   5 | Train loss: 1.051 | Val loss: 1.637 | Gen: ehay arway ondway isway oway\n",
            "Epoch:   6 | Train loss: 0.950 | Val loss: 1.283 | Gen: etay arway ondinday isway oway\n",
            "Epoch:   7 | Train loss: 0.817 | Val loss: 1.212 | Gen: etway arway ondiningngngngngngna isway oway\n",
            "Epoch:   8 | Train loss: 0.717 | Val loss: 1.212 | Gen: eetehay arway ondngngnday isway oway\n",
            "Epoch:   9 | Train loss: 0.681 | Val loss: 1.057 | Gen: etehway iray ondiningngngngngcay isway oingrigway\n",
            "Epoch:  10 | Train loss: 0.579 | Val loss: 1.019 | Gen: ethay arway ondiningcangcay isway oinway\n",
            "Epoch:  11 | Train loss: 0.507 | Val loss: 1.016 | Gen: ethay irarway onnintiningcangcay isway oingray\n",
            "Epoch:  12 | Train loss: 0.480 | Val loss: 0.895 | Gen: etehay arway ondtingngcay isway oringway\n",
            "Epoch:  13 | Train loss: 0.439 | Val loss: 0.981 | Gen: eththay irway ondintiongcay isway oringingway\n",
            "Epoch:  14 | Train loss: 0.448 | Val loss: 0.947 | Gen: etehay arirway ondiningcatingcay isway owingway\n",
            "Epoch:  15 | Train loss: 0.380 | Val loss: 0.778 | Gen: ethway irway ondiniongcay isway orkgingway\n",
            "Epoch:  16 | Train loss: 0.316 | Val loss: 0.782 | Gen: ethay irway onditioningcay isway oringigway\n",
            "Epoch:  17 | Train loss: 0.294 | Val loss: 0.835 | Gen: ethay irway ondiniongcay isway orkingway\n",
            "Epoch:  18 | Train loss: 0.260 | Val loss: 0.742 | Gen: tehway irway ondintioncway isway orkingway\n",
            "Epoch:  19 | Train loss: 0.222 | Val loss: 0.744 | Gen: ehethway irway ondinioncingcway isway orkingway\n",
            "Epoch:  20 | Train loss: 0.189 | Val loss: 0.722 | Gen: ethay irwarway ondinitionway isway orkingway\n",
            "Epoch:  21 | Train loss: 0.173 | Val loss: 0.739 | Gen: ethay irwarway ondiniongcay isway orkingway\n",
            "Epoch:  22 | Train loss: 0.165 | Val loss: 0.771 | Gen: ethay irwarwway onndiioningcay isway ooringway\n",
            "Epoch:  23 | Train loss: 0.177 | Val loss: 0.770 | Gen: ehay irway ondintioncingcay isway orkingway\n",
            "Epoch:  24 | Train loss: 0.172 | Val loss: 0.735 | Gen: ethay arwway onditioningcay isway orkingway\n",
            "Epoch:  25 | Train loss: 0.186 | Val loss: 1.065 | Gen: tehway arirway ondintioncway isway orkingway\n",
            "Epoch:  26 | Train loss: 0.247 | Val loss: 0.719 | Gen: eethay irway ondigioningcay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.163 | Val loss: 0.655 | Gen: ehtway irway onditiongcingcay isway orkingway\n",
            "Epoch:  28 | Train loss: 0.121 | Val loss: 0.622 | Gen: ethay irrway onditioningcay isway okingray\n",
            "Epoch:  29 | Train loss: 0.102 | Val loss: 0.608 | Gen: ehthay irirway onditioningcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.089 | Val loss: 0.626 | Gen: ethay irway onditiongcay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.096 | Val loss: 0.816 | Gen: ethay irrway onnditioningciningci isway orkingway\n",
            "Epoch:  32 | Train loss: 0.194 | Val loss: 0.641 | Gen: ethay irway onnditiongcnway isway owringway\n",
            "Epoch:  33 | Train loss: 0.145 | Val loss: 0.631 | Gen: ethay irway onditionclay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.095 | Val loss: 0.534 | Gen: ethay irwarwway onditiongcay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.063 | Val loss: 0.535 | Gen: ehay irrway onditingcay isway okingray\n",
            "Epoch:  36 | Train loss: 0.048 | Val loss: 0.524 | Gen: ethay irway onditiongcay isway okingway\n",
            "Epoch:  37 | Train loss: 0.039 | Val loss: 0.566 | Gen: ethay irway onditionclay isway okingway\n",
            "Epoch:  38 | Train loss: 0.036 | Val loss: 0.567 | Gen: ethay irway onditiongcay isway okingway\n",
            "Epoch:  39 | Train loss: 0.030 | Val loss: 0.586 | Gen: ethay irway onditiongcay isway okingway\n",
            "Epoch:  40 | Train loss: 0.026 | Val loss: 0.581 | Gen: ethay irway onditiongcay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.023 | Val loss: 0.594 | Gen: ethay irway onditionclay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.024 | Val loss: 0.610 | Gen: ethay irway onditiongcay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.035 | Val loss: 0.800 | Gen: ethay iway onditioncingcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.124 | Val loss: 0.832 | Gen: ehay iwayway onnditingcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.163 | Val loss: 0.721 | Gen: ethay arway onditiongcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.188 | Val loss: 0.876 | Gen: ehay irway onditonoongay isway okingray\n",
            "Epoch:  47 | Train loss: 0.190 | Val loss: 0.518 | Gen: ehway irway onnditiongcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.093 | Val loss: 0.445 | Gen: ehay irway onnditiongcay isway orkingway\n",
            "Epoch:  49 | Train loss: 0.055 | Val loss: 0.437 | Gen: ehay irway onnditiongcay isway orkingway\n",
            "Obtained lowest validation loss of: 0.4370648428797722\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tehay irway onnditiongcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dardK4RWvUWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3133d5-d9e8-4f91-d5fa-a58a6fb66c12"
      },
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "trans64_args_l = AttrDict()\n",
        "args_dict = {\n",
        "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
        "              'cuda':True, \n",
        "              'nepochs':50,\n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':5e-4,\n",
        "              'early_stopping_patience': 20,\n",
        "              'lr_decay':0.99,\n",
        "              'batch_size': 512, \n",
        "              'hidden_size': 64, # Increased model size\n",
        "              'encoder_type': 'transformer',\n",
        "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
        "              'num_transformer_layers': 3,\n",
        "}\n",
        "trans64_args_l.update(args_dict)\n",
        "print_opts(trans64_args_l)\n",
        "\n",
        "trans64_encoder_l, trans64_decoder_l, trans64_losses_l = train(trans64_args_l)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_l, trans64_decoder_l, None, trans64_args_l)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                         data_file_name: pig_latin_large                        \n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 50                                     \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.0005                                 \n",
            "                early_stopping_patience: 20                                     \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 512                                    \n",
            "                            hidden_size: 64                                     \n",
            "                           encoder_type: transformer                            \n",
            "                           decoder_type: transformer                            \n",
            "                 num_transformer_layers: 3                                      \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('newcomers', 'ewcomersnay')\n",
            "('lq', 'lqay')\n",
            "('contracting', 'ontractingcay')\n",
            "('garde', 'ardegay')\n",
            "('transexual', 'ansexualtray')\n",
            "Num unique word pairs: 22402\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.415 | Val loss: 1.921 | Gen: eway iay intntintintintinay iay onay\n",
            "Epoch:   1 | Train loss: 1.706 | Val loss: 1.667 | Gen: etay-ay-ay-ay-ay ay-ay-ay inway-ingcay iway onay-ay-inay\n",
            "Epoch:   2 | Train loss: 1.504 | Val loss: 1.606 | Gen: etay iay ontinay-inay isway oray-inay\n",
            "Epoch:   3 | Train loss: 1.320 | Val loss: 1.467 | Gen: etway iaray ontionway-inway isway onay-ay-inway\n",
            "Epoch:   4 | Train loss: 1.187 | Val loss: 1.457 | Gen: etay-ay-eway aiay onontionnnnnnnay isway ongay-ay-inway\n",
            "Epoch:   5 | Train loss: 1.112 | Val loss: 1.456 | Gen: atay-ay-ay arway ondingway-ay-ongngwa asway ogay-away-ay\n",
            "Epoch:   6 | Train loss: 1.029 | Val loss: 1.363 | Gen: ethway arway ondingay-innngngay iway oway-ingway\n",
            "Epoch:   7 | Train loss: 0.903 | Val loss: 1.275 | Gen: ethay ariway ondionway-inway isway ongay-ingway\n",
            "Epoch:   8 | Train loss: 0.827 | Val loss: 1.319 | Gen: ethay ariway otay-inday-ingngngay isway oway-ingway\n",
            "Epoch:   9 | Train loss: 0.775 | Val loss: 1.105 | Gen: ethway arway ontionndannnnngngay iwsway oway-inway\n",
            "Epoch:  10 | Train loss: 0.695 | Val loss: 1.076 | Gen: ehay-hay ariway ondidididiongngway isway oway-ingway\n",
            "Epoch:  11 | Train loss: 0.607 | Val loss: 1.045 | Gen: ethay-away ariray otindingcay-ongngay isway orway-ingway\n",
            "Epoch:  12 | Train loss: 0.563 | Val loss: 0.958 | Gen: ehthay ariway ondioniongngay-ngay isway oway-ingway\n",
            "Epoch:  13 | Train loss: 0.510 | Val loss: 0.986 | Gen: ethay irway ondictincaningay isway orkway-ingway\n",
            "Epoch:  14 | Train loss: 0.489 | Val loss: 0.821 | Gen: ethay airway onditiongngngngay isway orway-ingway\n",
            "Epoch:  15 | Train loss: 0.426 | Val loss: 0.771 | Gen: ethay ariway odniontiongnay isway orkngingway\n",
            "Epoch:  16 | Train loss: 0.373 | Val loss: 0.761 | Gen: ethay ariway onditiongniongcay isway orkingway\n",
            "Epoch:  17 | Train loss: 0.344 | Val loss: 0.775 | Gen: ethay ariway ondictioncany isway orkngingway\n",
            "Epoch:  18 | Train loss: 0.319 | Val loss: 0.706 | Gen: ethay ariway onditioncingngay isway orkingngway\n",
            "Epoch:  19 | Train loss: 0.295 | Val loss: 0.944 | Gen: ethay ariway onditiongninay isway orkingway\n",
            "Epoch:  20 | Train loss: 0.347 | Val loss: 1.119 | Gen: hethay arway ondicitiongningcay isway orkingray\n",
            "Epoch:  21 | Train loss: 0.441 | Val loss: 1.022 | Gen: ehay airay onditiongnionay isay orkgigngway\n",
            "Epoch:  22 | Train loss: 0.355 | Val loss: 0.730 | Gen: ethay airway onditioniongngngcay isay okngingway\n",
            "Epoch:  23 | Train loss: 0.255 | Val loss: 0.598 | Gen: ethay airway onditiongningnay isway orkingway\n",
            "Epoch:  24 | Train loss: 0.214 | Val loss: 0.631 | Gen: ethay airway odnitioningninay isway orkingway\n",
            "Epoch:  25 | Train loss: 0.200 | Val loss: 0.556 | Gen: ethay airway onditiongningngngay isway orkingngway\n",
            "Epoch:  26 | Train loss: 0.172 | Val loss: 0.512 | Gen: ethay airway onditioningninay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.154 | Val loss: 0.528 | Gen: ethay airway onditiongningngcay isway orkingway\n",
            "Epoch:  28 | Train loss: 0.143 | Val loss: 0.490 | Gen: ethay airway onditioniongcay isway orkingway\n",
            "Epoch:  29 | Train loss: 0.137 | Val loss: 0.542 | Gen: ehay airway onditiongingcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.129 | Val loss: 0.452 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.110 | Val loss: 0.437 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  32 | Train loss: 0.110 | Val loss: 0.495 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  33 | Train loss: 0.118 | Val loss: 0.520 | Gen: hetay airway onditioniongcay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.141 | Val loss: 0.818 | Gen: etay aiiway onditioningy isway orkingway\n",
            "Epoch:  35 | Train loss: 0.267 | Val loss: 1.252 | Gen: thay arway ondintingcany isway orkwinwnway\n",
            "Epoch:  36 | Train loss: 0.315 | Val loss: 0.497 | Gen: etay airway onditiongingcay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.170 | Val loss: 0.499 | Gen: ethay irway onditioningcay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.118 | Val loss: 0.376 | Gen: ethay airway onditiongningcay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.086 | Val loss: 0.317 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.067 | Val loss: 0.310 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.058 | Val loss: 0.293 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.050 | Val loss: 0.290 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.046 | Val loss: 0.277 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.042 | Val loss: 0.281 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.036 | Val loss: 0.279 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.032 | Val loss: 0.277 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.030 | Val loss: 0.277 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.033 | Val loss: 0.285 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  49 | Train loss: 0.034 | Val loss: 0.308 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Obtained lowest validation loss of: 0.276622651008298\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSSyiG39vVlN"
      },
      "source": [
        "The following cell generates two loss plots. In the first plot, we compare the effects of increasing dataset size. In the second plot, we compare the effects of increasing model size. Include both plots in your report, and include your analysis of the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ql0pxrEvVP6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a5722ab7-9267-4850-83db-59b201cde879"
      },
      "source": [
        "save_loss_comparison_by_dataset(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_dataset')\n",
        "save_loss_comparison_by_hidden(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_hidden')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBnBXRG8mvcn"
      },
      "source": [
        "# Optional: Attention Visualizations\n",
        "\n",
        "One of the benefits of using attention is that it allows us to gain insight into the inner workings of the model.\n",
        "\n",
        "By visualizing the attention weights generated for the input tokens in each decoder step, we can see where the model focuses while producing each output token.\n",
        "\n",
        "The code in this section loads the model you trained from the previous section and uses it to translate a given set of words: it prints the translations and display heatmaps to show how attention is used at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqEC0vN9mvpV"
      },
      "source": [
        "## Step 1: Visualize Attention Masks\n",
        "Play around with visualizing attention maps generated by the previous two models you've trained. Inspect visualizations in one success and one failure case for both models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkfz-u-MtudL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c6ac4791-c3f9-496e-f970-11948250613d"
      },
      "source": [
        "TEST_WORD_ATTN = 'street'\n",
        "visualize_attention(TEST_WORD_ATTN, rnn_attn_encoder, rnn_attn_decoder, None, args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-5075212dbc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTEST_WORD_ATTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'street'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_WORD_ATTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_attn_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_attn_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssa7g35zt2yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6d6b1ec8-85fb-45fd-afbf-df351c1ddcfd"
      },
      "source": [
        "TEST_WORD_ATTN = 'street'\n",
        "visualize_attention(TEST_WORD_ATTN, transformer_encoder, transformer_decoder, None, args, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-03e083f911fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTEST_WORD_ATTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'street'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_WORD_ATTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'transformer_encoder' is not defined"
          ]
        }
      ]
    }
  ]
}